<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>5</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="style.css" />
  <script>
    window.MathJax = {
      loader: { load: ['[tex]/newcommand', '[tex]/boldsymbol'] },
      tex: {
        packages: { '[+]': ['base', 'ams', 'newcommand', 'boldsymbol'] },
        macros: {
          bm: ["\\boldsymbol{#1}", 1]  // Define \bm{} using \boldsymbol{}
        },
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


      
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
    $$
    \newcommand{\Answer}{\begin{tcolorbox}}
    \newcommand{\Answerend}{\end{tcolorbox}}
    \newcommand{\ket}[1]{|#1\rangle}
    \newcommand{\bra}[1]{\langle#1|}
    \newcommand{\ip}[2]{\langle#1|#2\rangle}
    \newcommand{\bip}[2]{\left\langle#1\middle|#2\right\rangle}
    \newcommand{\qexp}[1]{\langle#1\rangle}
    \newcommand{\apos}[1]{``#1"}
    \newcommand{\sapos}[1]{`#1'}
    \newcommand{\elec}{e^{-}}
    \newcommand{\uspin}{(\uparrow)}
    \newcommand{\dspin}{(\downarrow)}
    \newcommand{\lspin}{(\leftarrow)}
    \newcommand{\rspin}{(\rightarrow)}
    \newcommand{\ulspin}{(\uparrow\leftarrow)}
    \newcommand{\urspin}{(\uparrow\rightarrow)}
    \newcommand{\dlspin}{(\downarrow\leftarrow)}
    \newcommand{\drspin}{(\downarrow\rightarrow)}
    \newcommand{\R}{\mathbb{R}}
    \newcommand{\stab}{\:\:}
    \newcommand{\mtab}{\:\:\:}
    \newcommand{\btab}{\:\:\:}
    \newcommand{\imp}{\Rightarrow}
    \newcommand{\doubimp}{\Leftrightarrow}
    \newcommand{\setof}[1]{\{#1\}}
    \newcommand{\infint}{\int_{-\infty}^{\infty}}
    \newcommand{\trans}[1]{\mathcal{T}(#1)}
    \newcommand{\dd}[2]{\delta(#1-#2)}
    \newcommand{\ipbig}[2]{\langle#1|#2\rangle}
    \newcommand{\talpha}{\tilde{\alpha}}
    \newcommand{\op}[2]{|#1\rangle\langle#2|}
    \newcommand{\sop}[1]{|#1\rangle\langle#1|}
    \newcommand{\prop}[2]{\mathcal{U}(#1,#2)}
    \newcommand{\propdagg}[2]{\mathcal{U}^{\dagger}(#1,#2)}
    \newcommand{\sip}[1]{\langle#1|#1\rangle}
    \newcommand{\optrip}[3]{\langle#1|\hat{#2}|#3\rangle}
    \newcommand{\nhoptrip}[3]{\langle#1|{#2}|#3\rangle}
    \newcommand{\northexp}[2]{\sum_{i=1}^{n}|#2\rangle\langle#2|#1\rangle}
    \newcommand{\orthexp}[4]{\sum_{#3=1}^#4|#2\rangle\langle#2|#1\rangle}
    \newcommand{\schrodeq}{i\hbar\frac{\partial \Psi(x,t)}{\partial t}=\hat{H}\Psi(x,t)}
    \newcommand{\nd}[2]{\frac{d#1}{d #2}}
    \newcommand{\snd}[2]{\frac{d^{2}#1}{d#2^2}}
    \newcommand{\pd}[2]{\frac{\partial#1}{\partial #2}}
    \newcommand{\spd}[2]{\frac{\partial^{2}#1}{\partial #2^2}}
    \newcommand{\duac}{\leftrightarrow}
    \newcommand{\oip}[2]{\left(#1,#2\right)}
    \newcommand{\obip}[2]{\left(#1,#2\right)}
    $$
<h1 id="chapter-5-commutation-relations-and-simultaneous-states">Chapter
5: Commutation Relations and Simultaneous States</h1>
<p>Another question still remains. We know that state vectors represent
states– and that is, physical states. If we think to use our classical
intuition, we know a physical state can be thought about from the
perspective of one observable (such as when we consider the momentum of
two colliding objects). However, that does not mean it does not possess
any values for all other physical observables, as it still has energy,
angular momentum, and so on: only that we are not currently considering
the other observables. Similarly, we would not be particularly pleased
if the physical states pertaining to a certain measurement of one
specific observable– these so called pure states– suddenly contained
absolutely no information on any other observables. This is a question
of information encapsulation: how does an energy pure state store
extractable information about momentum, for example? To understand this
question, which is far more complicated than the classical one of “it’s
there, and just hasn’t been measured yet”, we treat the two seminal
theorems on the matter.<br />
<br />
It turns out that much of this information, on whether a state made hold
certain values for both observables represented by a given pair of
observable operators– in short, whether it can be a <strong>simultaneous
state</strong> for these two observables– turns out to be related
intimately with their <em>commutation relation</em>. That is, if we
define the <strong>commutator</strong> <span
class="math display">\[[\hat{A},\hat{B}] :=
\hat{A}\hat{B}-\hat{B}\hat{A}\]</span> then the specific value of this
commutator relates to our question of “simultaneous states".<br />
<br />
Here, we explore more consequences of the commutation relation between
two arbitrary observable operators. Along the way, we will also be able
to practise the mathematical operations we have introduced at a level
and intensity we have not had the occasion to do so far.</p>
<h2 id="simultaneous-states">Simultaneous states</h2>
<p>The question of “simultaneous states” is to investigate which states
(<span class="math inline">\(\leftrightarrow\)</span> state vectors) can
contain information on multiple observables at a time, and which
observables these are. We have seen in the Stern Gerlach experiment that
for example <span class="math inline">\(x\)</span> and <span
class="math inline">\(y\)</span> spin simultaneous states are
impossible, so this is a relevant, fully quantum in nature,
problem.<br />
<br />
It turns out that the ability for different observables to have
information represented in the same state vectors depends strongly on
the commutator of their observable operators, as these in turn relate
their orthonormal eigenvectors. To see this, there is one sweeping but
simple theorem on operators for observables which can be measured
simultaneously, and one dramatically anticlassical one for observables
which cannot.</p>
<h3 id="the-compatibility-theorem">The Compatibility Theorem</h3>
<p>Consider an unperturbed system, two physical observables, and three
measurements ordered chronologically. The first and third measurements
are for the first physical observable denoted <span
class="math inline">\(\mathcal{A}\)</span>, but the second measurement
is for the second observable <span
class="math inline">\(\mathcal{B}\)</span>. We know from the Measurement
Postulate that:</p>
<ul>
<li><p>The first measurement forces the wavefunction into some pure
eigenstate <span class="math inline">\(\bm{\alpha_{i}}\)</span> of the
first physical observable operator <span
class="math inline">\(\hat{A}\)</span>.</p></li>
<li><p>The second measurement forces the wavefunction into some pure
eigenstate <span class="math inline">\(\bm{\beta}_{i}\)</span> of the
second physical observable operator <span
class="math inline">\(\hat{B}\)</span>.</p></li>
<li><p>If the second measurement of the different observable did not
exist, then we would have successive measurements of the same state
(which is, the operator acting on the same pure state the starting state
vector was forced into following the first measurement) and we would
expect with certainty the same measured value of <span
class="math inline">\(\mathcal{A}\)</span> which is the eigenvalue <span
class="math inline">\(A_{i}\)</span> associated with the pure state
<span class="math inline">\(\bm{\alpha_{i}}\)</span>.</p></li>
</ul>
<p>The question is therefore whether or not this second measurement
changes the result of the third. This is a profound question, because if
it does, then we would conclude the simple act of measuring the second
observable has moved the state vector out of the pure eigenstate it was
in after the first measurement; that would then imply the second
measurement is in itself a perturbation to the system: a confusing
result. Indeed– the reader will recognise that this is exactly the class
of behaviour which appeared so surpisingly in the Stern Gerlach
experiment.<br />
<br />
We define <span class="math inline">\(\mathcal{A}\)</span> and <span
class="math inline">\(\mathcal{B}\)</span> to be <strong>compatible
observables</strong> iff the first and third measurements yield the same
value regardless of the starting state before measurement 1, and
regardless of the value of the second observable measured in the second
measurement. If we call the values measured <span
class="math inline">\(\mathcal{A}^{(1)}\)</span>, <span
class="math inline">\(\mathcal{B}^{(1)}\)</span>, <span
class="math inline">\(\mathcal{A}^{(2)}\)</span>, then observable <span
class="math inline">\(\mathcal{A}\)</span> and <span
class="math inline">\(\mathcal{B}\)</span> are compatible iff <span
class="math display">\[\forall\:\Psi,\:\forall\:\mathcal{B}^{(1)},\:\:\mathcal{A}^{(1)}=\mathcal{A}^{(2)}.\]</span>
<u><strong>Compatibility Theorem</strong></u>:<br />
<br />
The following three conditions all equivalent to each other:</p>
<ol>
<li><p><span class="math inline">\(\mathcal{A}\)</span> and <span
class="math inline">\(\mathcal{B}\)</span> are compatible
observables.</p></li>
<li><p><span class="math inline">\(\hat{A}\)</span> and <span
class="math inline">\(\hat{B}\)</span> share a common
eigenbasis.</p></li>
<li><p><span class="math inline">\(\hat{A}\)</span> and <span
class="math inline">\(\hat{B}\)</span> commute.</p></li>
</ol>
<p><br />
<br />
<u>Proof:</u><br />
<br />
First we prove that <span class="math inline">\(\hat{A}\)</span>
commutes with <span class="math inline">\(\hat{B}\)</span> iff they
possess a common eigenbasis.<br />
<br />
Consider two observable operators which commute, and define their
eigenbases to be <span
class="math inline">\(\{\bm{\alpha}_{i}\}\)</span> and <span
class="math inline">\(\{\bm{\beta}_{i}\}\)</span>. Now take an arbitrary
eigenvector <span class="math inline">\(\bm{\alpha}_{i}\)</span> of
<span class="math inline">\(\hat{A}\)</span> with eigenvalue <span
class="math inline">\(A_{i}\)</span>. We have <span
class="math display">\[\hat{A}\hat{B}=\hat{B}\hat{A}\]</span> so we get
<span
class="math display">\[\hat{A}\hat{B}\bm{\alpha}_{i}=\hat{B}\hat{A}\bm{\alpha}_{i}=\hat{B}A_{i}\bm{\alpha}_{i}.\]</span>
However, we can now pull the constant eigenvalue out: <span
class="math display">\[\hat{A}(\hat{B}\bm{\alpha}_{i})=A_{i}(\hat{B}\bm{\alpha}_{i})\]</span>
so clearly <span class="math inline">\(\hat{B}\bm{\alpha}_{i}\)</span>
is an eigenvector of <span class="math inline">\(\hat{A}\)</span>
corresponding to eigenvalue <span class="math inline">\(A_{i}\)</span>.
Assuming that the eigenvalues are nondegenerate this implies that <span
class="math inline">\(\hat{B}(\bm{\alpha}_{i})\)</span> coincides with
<span class="math inline">\(\bm{\alpha}_{i}\)</span> as the eigenvalue
<span class="math inline">\(A_{i}\)</span> has only one distinguishable
eigenvector. The fact that <span
class="math display">\[\hat{B}\bm{\alpha}_{i}\equiv\bm{\alpha}_{i}\]</span>
means we must have <span
class="math display">\[\hat{B}\bm{\alpha}_{i}=c\bm{\alpha}_{i}\]</span>
for some scalar multiple <span class="math inline">\(c\)</span>. This
means that <span class="math inline">\(\bm{\alpha}_{i}\)</span> is an
eigenvector of <span class="math inline">\(\hat{B}\)</span>
corresponding to eigenvalue <span class="math inline">\(c\)</span>. So
we can say that <span class="math inline">\(\forall\:i,
\bm{\alpha}_{i}\)</span> is an eigenvector of <span
class="math inline">\(\hat{A}\)</span> and <span
class="math inline">\(\hat{B}\)</span>: which means that they have the
same eigenbasis. This isn’t of course, to say, the eigenvalues are the
same for <span class="math inline">\(\hat{B}\)</span> and <span
class="math inline">\(\hat{A}\)</span> even though it may correspond to
the same eigenvector (above, they are not the same unless <span
class="math inline">\(A_{i}=c\)</span>). Yet at the same time this is
clearly helpful: if we know two physical observable operators commute
and we have the eigenbasis of one then we automatically have an
eigenbasis of the other.<br />
<br />
Now, we prove it the other way around. Assume <span
class="math inline">\(\hat{A}\)</span> and <span
class="math inline">\(\hat{B}\)</span> both possess the eigenbasis <span
class="math inline">\(\{\gamma_{i}\}\)</span>: that is, the vectors
<span class="math inline">\(\bm{\gamma}_{i}\)</span> are eigenvectors
for both <span class="math inline">\(\hat{A}\)</span> and <span
class="math inline">\(\hat{B}\)</span>. We want to prove they commute.
As they possess the same eigenbasis with eigenvalues <span
class="math inline">\(\{A_{i}\}\)</span> and <span
class="math inline">\(\{B_{i}\}\)</span> respectively, we can write
<span
class="math display">\[\hat{A}\hat{B}\gamma_{i}=\hat{A}B_{i}\gamma_{i}=B_{i}\hat{A}\gamma_{i}=B_{i}A_{i}\gamma_{i}\]</span>
and the exact same applies for <span
class="math inline">\(\hat{B}\hat{A}\gamma_{i}\)</span>: <span
class="math display">\[\hat{B}\hat{A}\gamma_{i}=\hat{B}A_{i}\gamma_{i}=A_{i}\hat{B}\gamma_{i}=A_{i}B_{i}\gamma_{i}.\]</span>
Clearly, as <span class="math inline">\(A_{i}\)</span> and <span
class="math inline">\(B_{i}\)</span> are constant eigenvalues, <span
class="math display">\[A_{i}B_{i}\equiv B_{i}A_{i}.\]</span> So this
easily proves that two observable operators possessing the same
eigenbasis must commute. Thus the implication works both ways and
therefore two observable operators commute iff they share a common
eigenbasis.<br />
<br />
Now to look at the practical definition: we are probably more interested
in the concept of compatibility, as it concerns whether or not a
measurement of a second observable in between measurements of a first
observable will alter the measured results from the first measurement,
effectively forcing the state vector out of the pure eigenstate it was
forced into. Let’s first prove that two observables having common
operator eigenbases is necessary and sufficient for the above defined
definition of compatibility to hold.<br />
<br />
Start by considering two observables <span
class="math inline">\(\mathcal{A}\)</span> and <span
class="math inline">\(\mathcal{B}\)</span> represented by operators
<span class="math inline">\(\hat{A}\)</span> and <span
class="math inline">\(\hat{B}\)</span> respectively. Define the
measurements to be <span
class="math inline">\(\mathcal{A}^{(1)},\mathcal{B}^{(1)}\)</span>,
<span class="math inline">\(\mathcal{A}^{(2)}\)</span>. For the
observables to be compatible we need <span
class="math inline">\(\mathcal{A}^{(1)}\)</span> to be the same as <span
class="math inline">\(\mathcal{A}^{(2)}\)</span> regardless of the
starting state and <span
class="math inline">\(\mathcal{B}^{(2)}\)</span>. Assume to begin with
that the two operators <span class="math inline">\(\hat{A}\)</span> and
<span class="math inline">\(\hat{B}\)</span> have the common eigenbasis
<span class="math inline">\(\{\gamma_{i}\}\)</span>. By definition the
first measurement of <span class="math inline">\(\mathcal{A}\)</span>
must force the state vector into a single eigenvector in the eigenbasis
of the operator <span class="math inline">\(\hat{A}\)</span>: that is,
some <span class="math inline">\(\gamma_{i}\)</span> such that the
measured value is for observable <span
class="math inline">\(\mathcal{A}\)</span> the eigenvalue <span
class="math inline">\(A_{i}\)</span>. Next, measurement <span
class="math inline">\({{B}}^{(1)}\)</span> is the action of the operator
<span class="math inline">\(\hat{B}\)</span> on the eigenvector <span
class="math inline">\(\gamma_{i}\)</span>. But by the Measurement
Postulate of quantum mechanics, <span
class="math display">\[P(\bm{\alpha}_{i})=|\oip{\bm{\alpha}_{i}}{\Psi}|^2\]</span>
That is, the probability that the arbitrary operator <span
class="math inline">\(\hat{A}\)</span> forces the state vector into an
arbitrary eigenvector <span
class="math inline">\(\bm{\alpha}_{i}\)</span> from its eigenbasis.
Here, then, since the state vector has been forced into the eigenstate
<span class="math inline">\(\gamma_{i}\)</span> by the first
measurement, the probability the second measurement of the other
observable <span class="math inline">\(\mathcal{B}\)</span> forces the
state vector into the same eigenstate is: <span
class="math display">\[P(\gamma_{i})=|\oip{\gamma_{i}}{\gamma_{i}}|^2=1\]</span>
where we assume as per usual that the eigenvectors <span
class="math inline">\(\gamma_{i}\)</span> have been normalised. So we
can say that measurement B will not alter the eigenstate the state
vector is in and therefore the third measurement will follow the same
logic to yield the exact same value, the eigenvalue <span
class="math inline">\(A_{i}\)</span> corresponding to <span
class="math inline">\(\gamma_{i}\)</span>. Thus, if two observable
operators possess the same eigenbasis, they are compatible
observables.<br />
<br />
If the observables are compatible then this implies their operators have
the same eigenbasis. The proof for this is simple. If the observables
<span class="math inline">\(\mathcal{A}\)</span> and <span
class="math inline">\(\mathcal{B}\)</span> are compatible then for the
successive measurements <span
class="math inline">\(\mathcal{A}^{(1)},\mathcal{B}^{(1)},\mathcal{A}^{(2)}\)</span>
the measured values for <span
class="math inline">\(\mathcal{A}^{(1)}\)</span> and <span
class="math inline">\(\mathcal{A}^{(2)}\)</span> must be the same. The
measurement <span class="math inline">\(\mathcal{A}^{(1)}\)</span> must
have forced the wavefunction into an eigenvector of <span
class="math inline">\(\hat{A}\)</span>, some arbitrary <span
class="math inline">\(\bm{\alpha}_{i}\)</span>. Then, the measurement
<span class="math inline">\(\mathcal{B}^{(1)}\)</span> must force the
wavefunction into some arbitrary eigenvector <span
class="math inline">\(\bm{\beta}_{i}\)</span> of the operator <span
class="math inline">\(\hat{B}\)</span>. However, the final measurement
must yield the same result as the first if the observables are
compatible, which is, the same eigenvalue corresponding to the same
eigenvector <span class="math inline">\(\bm{\alpha}_{i}\)</span> of
operator <span class="math inline">\(\hat{A}\)</span> as it originally
was in. The probability that the measurement forces the wavefunction,
currently in the eigenstate <span
class="math inline">\(\bm{\beta}_{i}\)</span> of <span
class="math inline">\(\hat{B}\)</span> as the measurement <span
class="math inline">\(\mathcal{B}^{(1)}\)</span> has just been
performed, into the same eigenstate <span
class="math inline">\(\bm{\alpha}_{i}\)</span> as originally measured
is: <span
class="math display">\[P(\bm{\alpha}_{i})=|\oip{\bm{\alpha}_{i}}{\bm{\beta}_{i}}|^2.\]</span>
However, if these observables are to be compatible, the final
measurement must with certainty yield the eigenvalue <span
class="math inline">\(A_{i}\)</span> again and therefore the above
probability of measurement <span
class="math inline">\(\mathcal{A}^{(2)}\)</span> forcing it back into
the original eigenstate must be 1. So <span
class="math display">\[|\oip{\bm{\alpha}_{i}}{\bm{\beta}_{i}}|^2=1
\Rightarrow\:\: \bm{\alpha}_{i}\equiv\bm{\beta}_{i}\]</span> and
therefore their eigenbases must be the same as the above holds true for
any arbitrary <span class="math inline">\(\bm{\alpha}_{i}\)</span> and
corresponding <span class="math inline">\(\bm{\beta}_{i}\)</span> from
the measurements.<br />
<br />
The Compatibility Theorem is now complete. We have shown that:</p>
<ul>
<li><p>Two operators commuting is necessary and sufficient for them to
possess a common eigenbasis.</p></li>
<li><p>Two operators possessing a common eigenbasis is necessary and
sufficient for the two observables they represent to be
compatible.</p></li>
<li><p>Therefore, two observable operators commuting is also necessary
and sufficient for them to represent compatible observables.</p></li>
</ul>
<p>The logical implications of these facts all run three ways.<br />
<br />
While we have now seen facts about compatible observables, an example of
incompatible observables sticks in our mind– that of the Stern Gerlach
experiment. We saw exactly that <span class="math inline">\(x\)</span>
and <span class="math inline">\(y\)</span> spins were incompatible,
because measuring the <span class="math inline">\(x\)</span> spin in
between two <span class="math inline">\(y\)</span> measurements stopped
the second <span class="math inline">\(y\)</span> measurement from being
the same as the first with certainty– which is to say, we now know, that
the measurement of <span class="math inline">\(x\)</span> spin forced it
out of the eigenstate of <span class="math inline">\(y\)</span> spin it
had been previously forced into. All the questions about the quantum
state raised by the Stern Gerlach experiment will finally come to an end
with this section. We would like to formalise our understanding of how
incompatibility affected the experiment. To explain it all, we witness–
and prove ourselves– one of Physics’ most groundbreaking and shocking
theorems, the famous <strong>Heisenberg Uncertainty
Principle</strong>.</p>
<h2 id="the-heisenberg-uncertainty-principle">The Heisenberg Uncertainty
Principle</h2>
<p>The idea of commuting observable operators being necessary and
sufficient for the two observables they represent to be compatible is a
very important one for the question of simultaneous states, and has been
shown above. Now we must surely consider when two observable operators
do not commute: in other words, when they represent
<strong>incompatible</strong> observables. One of the most important and
dramatic results of all quantum mechanics, the Heisenberg Uncertainty
Principle, results when we carry out some elegant mathematics to
investigate this problem. Before we begin the statement and proof, let
us define the commutator between two operators to be <span
class="math display">\[[\hat{A},\hat{B}]:=\hat{A}\hat{B}-\hat{B}\hat{A}\]</span>
so that if we have two commuting operators <span
class="math inline">\(\hat{A}\)</span> and <span
class="math inline">\(\hat{B}\)</span>, then <span
class="math display">\[[\hat{A},\hat{B}]=\hat{A}\hat{B}-\hat{B}\hat{A}=0\]</span>
since <span class="math inline">\(\hat{A}\hat{B}=\hat{B}\hat{A}\)</span>
iff they commute. For operators which do not commute, their commutator
may take a wide variety of forms: which is why it is useful under
universal convention to have this shorthand.</p>
<div class="tcolorbox">
<p><strong><u>Heisenberg Uncertainty Principle</u></strong><br />
<br />
For any state <span class="math inline">\(\Psi_{t}\)</span>, <span
class="math display">\[\Delta A_{t}\Delta
B_{t}\geq\frac{1}{2}|\oip{\Psi_{t}}{[\hat{A},\hat{B}]\Psi_{t}}|\]</span>
where <span class="math inline">\(\Delta A_{t}\)</span> is the standard
deviation of measurable values of observable <span
class="math inline">\(\mathcal{A}\)</span> at time <span
class="math inline">\(t\)</span>: which is therefore a measure of
uncertainty for these variables.</p>
</div>
<p><u><strong>Proof:</strong></u><br />
<br />
We will continue to refer to arbitrary observables <span
class="math inline">\(\mathcal{A}\)</span> and <span
class="math inline">\(\mathcal{B}\)</span> for the proof; all the proof
is relevant at any instant of time and so time subscripts will be
eschewed. The notation <span class="math inline">\(\Delta A\)</span>
refers to the standard deviation of the measurements of observable <span
class="math inline">\(\mathcal{A}\)</span>; this standard deviation is
no different from the statistical definition: <span
class="math display">\[\Delta A=\sqrt{\langle \hat{A}^2\rangle-\langle
\hat{A}\rangle^2}\]</span> where the symbol <span
class="math inline">\(\langle X\rangle\)</span> is the expected value of
the variable <span class="math inline">\(X\)</span>, as seen in the
probability preliminary. First we note that this principle is valid for
compatible observables: as compatible observables, their operators must
commute. Thus <span class="math display">\[[\hat{A},\hat{B}]=0
\Rightarrow\:\: \Delta A_{t}\Delta
B_{t}\geq\frac{1}{2}|\oip{\Psi_{t}}{[\hat{A},\hat{B}]\Psi_{t}}| =
\frac{1}{2}|\oip{\Psi_{t}}{0} |=0.\]</span> So for compatible
observables, <span class="math display">\[\Delta A_{t}\Delta B_{t}\geq
0\]</span> which is neither interesting nor invalid at all since the
standard deviation of any measurement can never be negative. Now, we
will prove this for all physical operators, regardless of whether they
commute.<br />
<br />
<u><strong>Lemma 1:</strong></u><br />
Any operator <span
class="math inline">\(\hat{X}&#39;:=\hat{X}-\qexp{\hat{X}}\)</span>
where <span class="math inline">\(\hat{X}\)</span> is a Hermitian
physical operator is also Hermitian.<br />
<br />
<u><strong>Proof:</strong></u><br />
<br />
Recall that the definition for an expected value of a variable is the
sum of its possible values multiplied by the probabilities of the
variable taking those values. Therefore, we can say that, over the
eigenbasis <span class="math inline">\(\{\xi_{i}\}\)</span> of <span
class="math inline">\(\hat{X}\)</span> with eigenvalues <span
class="math inline">\(\{X_{i}\}\)</span>, <span
class="math display">\[\qexp{\hat{X}}=\sum_{\{i\}}P(\xi_{i})X_{i},\]</span>
but by our knowledge of the previous postulates we can describe the
probability more precisely: the measurement postulate defines this to be
<span
class="math display">\[\qexp{\hat{X}}=\sum_{\{i\}}X_{i}|\oip{\xi_{i}}{\Psi}|^2.\]</span>
Our job is to prove that the operator <span
class="math inline">\(\hat{X}&#39;:=\hat{X}-\qexp{\hat{X}}\)</span> is
hermitian if <span class="math inline">\(\hat{X}\)</span> is hermitian
for all quantum operators. That is, we need to prove that: <span
class="math display">\[\oip{\Psi_{1}}{\hat{X}&#39;\Psi_{2}}=\oip{\hat{X}&#39;\Psi_{1}}{\Psi_{2}}\]</span>
for all Hilbert space functions <span
class="math inline">\(\Psi_{1}\)</span> and <span
class="math inline">\(\Psi_{2}\)</span>. The operator <span
class="math inline">\(\hat{X}\)</span> must be hermitian as <span
class="math inline">\(\hat{X}\)</span> is defined to be a quantum
operator corresponding to a physical observable. Meanwhile, the
expectation value <span
class="math display">\[\qexp{\hat{X}}=\sum_{\{i\}}X_{i}|\oip{\xi_{i}}{\Psi}|^2.\]</span>
is clearly a real scalar, as the probabilities, which are square moduli,
will all be real numbers and so will each eigenvalue of the hermitian
operators. Therefore, <span
class="math display">\[\oip{\hat{X}\Psi_{1}}{\Psi_{2}}\equiv\oip{\Psi_{1}}{\hat{X}\Psi_{2}}\]</span>
and <span
class="math display">\[\oip{\qexp{\hat{X}}\Psi_{1}}{\Psi_{2}}\equiv\oip{\Psi_{1}}{\langle\hat{X}\rangle\Psi_{2}}\equiv\qexp{\hat{X}}\oip{\Psi_{1}}{\Psi_{2}}\]</span>
so for any physical operator <span
class="math inline">\(\hat{X}\)</span> the defined operator <span
class="math inline">\(\hat{X}&#39;\)</span> is the sum of two hermitian
operators. So <span class="math display">\[\begin{aligned}
\oip{\hat{X}&#39;\Psi_{1}}{\Psi_{2}}&amp;=\oip{[\hat{X}-\langle\hat{X}\rangle]\Psi_{1}}{\Psi_{2}}=\oip{\hat{X}\Psi_{1}}{\Psi_{2}}-\oip{\langle\hat{X}\rangle\Psi_{1}}{\Psi_{2}}\\
&amp;=\oip{\Psi_{1}}{\hat{X}\Psi_{2}}-\oip{\Psi_{1}}{\langle\hat{X}\rangle\Psi_{2}}\\
&amp;=\oip{\Psi_{1}}{\hat{X}&#39;\Psi_{2}}
\end{aligned}\]</span> using the linear properties of the inner product.
Thus, the operator <span class="math inline">\(\hat{X}&#39;\)</span> is
Hermitian for any physical operator. Therefore, defining <span
class="math inline">\(\hat{A&#39;}:=\hat{A}-\qexp{\hat{A}}\)</span> and
<span
class="math inline">\(\hat{B}&#39;:=\hat{B}-\qexp{\hat{B}}\)</span> for
the purpose of the problem also gives us two hermitian operators. <span
class="math inline">\(\square\)</span><br />
<br />
The commutator in the generalised principle might give pause with
regards to the development of these new operators, but, importantly,
<span
class="math display">\[[\hat{A}&#39;,\hat{B}&#39;]=[\hat{A},\hat{B}].\]</span>
This fact can be proved quite simply: <span
class="math display">\[\begin{aligned}
[\hat{A}&#39;,\hat{B}&#39;]&amp;= \hat{A}&#39;\hat{B}&#39;-
\hat{A}&#39;\hat{B}&#39;\\
&amp;=
(\hat{A}-\qexp{\hat{A}})(\hat{B}-\qexp{\hat{B}})-(\hat{B}-\qexp{\hat{B}})
(\hat{A}-\qexp{\hat{A}})\\
&amp;=(\hat{A}\hat{B}-\hat{A}\qexp{\hat{B}}-\qexp{\hat{A}}\hat{B}-\qexp{\hat{A}}\qexp{\hat{B}})-(\hat{B}\hat{A}-\hat{B}\qexp{\hat{A}}-\qexp{\hat{B}}\hat{A}-\qexp{\hat{B}}\qexp{\hat{A}})
\end{aligned}\]</span> but as the expectation values <span
class="math inline">\(\qexp{\hat{A}}\)</span> and <span
class="math inline">\(\qexp{\hat{B}}\)</span> are real scalars it is
clear that <span
class="math inline">\(\qexp{\hat{A}}\qexp{\hat{B}}=\qexp{\hat{B}}\qexp{\hat{A}}\)</span>,
and <span
class="math inline">\(\qexp{\hat{A}}\hat{B}=\hat{B}\qexp{\hat{A}}\)</span>
and vice versa swapping the <span class="math inline">\(A\)</span> and
<span class="math inline">\(B\)</span> around. So the terms cancel out
and we are left with <span
class="math display">\[[\hat{A}&#39;,\hat{B}&#39;]=\hat{A}\hat{B}-\hat{B}\hat{A}:=[\hat{A},\hat{B}].
\:\:\square\]</span> Now, one last important lemma:<br />
<br />
<u><strong>Lemma 2:</strong></u><br />
<span
class="math display">\[\oip{\hat{A}&#39;\Psi}{\hat{A}&#39;\Psi}=(\Delta\hat{A})^2\]</span><br />
<br />
<u><strong>Proof:</strong></u><br />
By the Hermiticity of <span class="math inline">\(\hat{A}&#39;\)</span>,
<span
class="math display">\[\oip{\hat{A}&#39;\Psi}{\hat{A}&#39;\Psi}=\oip{\Psi}{([\hat{A}&#39;]^2\Psi}.\]</span>
Expanding the definition, <span class="math display">\[\begin{aligned}
\oip{\hat{A}&#39;\Psi}{\hat{A}&#39;\Psi}&amp;=\oip{\Psi}{\hat{A}&#39;^2\Psi}\\
&amp;=\oip{\Psi}{[\hat{A}-\qexp{\hat{A}}][\hat{A}-\qexp{\hat{A}}]\Psi}\\
&amp;=\oip{\Psi}{[\hat{A}^{2}]\Psi-2\qexp{\hat{A}}\hat{A}\Psi+\qexp{\hat{A}}^2\Psi}\\
&amp;=\oip{\Psi}{[\hat{A}^{2}]\Psi}-2\qexp{\hat{A}}\oip{\Psi}{\hat{A}\Psi}+\qexp{\hat{A}}^2\oip{\Psi}{\Psi}\\
&amp;=\langle\hat{A}^2\rangle\oip{\Psi}{\Psi}-2\qexp{\hat{A}}\qexp{\hat{A}}\oip{\Psi}{\Psi}+\qexp{\hat{A}}^2\oip{\Psi}{\Psi}\\
&amp;=
\langle\hat{A}^2\rangle-2\qexp{\hat{A}}\qexp{\hat{A}}+\qexp{\hat{A}}^2\\
&amp;=\langle\hat{A}^2\rangle-\qexp{\hat{A}}^2\\
&amp;=(\Delta\hat{A})^2 \:\:\:\:\:\:\square
\end{aligned}\]</span> Now we can use these lemmas to prove the problem.
We want to prove that <span
class="math display">\[\Delta{A}\Delta{B}\geq\frac{1}{2}|\oip{\Psi}{[\hat{A},\hat{B}]\Psi}|\]</span>
at all times <span class="math inline">\(t\)</span>. We start by
replacing <span class="math inline">\([\hat{A},\hat{B}]\)</span> with
<span class="math inline">\([\hat{A}&#39;,\hat{B}&#39;]\)</span>. Then,
we have, <span
class="math display">\[\oip{\Psi}{[\hat{A},\hat{B}]\Psi}=\oip{\Psi}{[\hat{A}&#39;,\hat{B}&#39;]\Psi}=\oip{\Psi}{[\hat{A}&#39;\hat{B}&#39;-\hat{B}&#39;\hat{A}&#39;]\Psi}.\]</span>
This is, <span
class="math display">\[\oip{\Psi}{[\hat{A},\hat{B}]\Psi}=\oip{\Psi}{\hat{A}&#39;\hat{B}&#39;\Psi}-\oip{\Psi}{\hat{B}&#39;\hat{A}&#39;\Psi}
.\]</span> We can rearrange this by the hermiticity of <span
class="math inline">\(\hat{A}&#39;\)</span> and <span
class="math inline">\(\hat{B}&#39;\)</span>: <span
class="math display">\[\oip{\Psi}{[\hat{A},\hat{B}]\Psi}=\oip{\hat{A}&#39;\Psi}{\hat{B}&#39;\Psi}-\oip{\hat{B}&#39;\Psi}{\hat{A}&#39;\Psi}=\oip{\hat{A}&#39;\Psi}{\hat{B}&#39;\Psi}-\oip{\hat{A}&#39;\Psi}{\hat{B}&#39;\Psi}^{\ast}\]</span>
so this is <span
class="math display">\[\oip{\Psi}{[\hat{A},\hat{B}]\Psi}=2i\text{Im}\left(\oip{\hat{A}&#39;\Psi}{\hat{B}&#39;\Psi}\right)\]</span>
according to rudimentary arithmetic of complex numbers. Then, the
expression we need is <span
class="math display">\[\frac{1}{2}|\oip{\Psi}{[\hat{A},\hat{B}]\Psi}|\leq\frac{1}{2}\times2|\oip{\hat{A}&#39;\Psi}{\hat{B}&#39;\Psi}|=|\oip{\hat{A}&#39;\Psi}{\hat{B}&#39;\Psi}|.\]</span>
This is because of the above expression for <span
class="math inline">\(\oip{\Psi}{[\hat{A},\hat{B}]\Psi}\)</span> and the
fact that the modulus of the imaginary part of a scalar cannot be
greater than the modulus of the scalar (Exercise 1.3.2a). Then, by Lemma
2 <span
class="math display">\[\oip{\hat{A}&#39;\Psi}{\hat{A}&#39;\Psi}=(\Delta\hat{A})^2\Rightarrow\:\:\Delta\hat{A}=\sqrt{\oip{\hat{A}&#39;\Psi}{\hat{A}&#39;\Psi}}.\]</span>
So <span
class="math display">\[\Delta\hat{A}\Delta\hat{B}=\sqrt{\oip{\hat{A}&#39;\Psi}{\hat{A}&#39;\Psi}}\sqrt{\oip{\hat{B}&#39;\Psi}{\hat{B}&#39;\Psi}}.\]</span>
By Cauchy-Schwartz, <span
class="math display">\[\sqrt{\oip{\hat{A}&#39;\Psi}{\hat{A}&#39;\Psi}}\sqrt{\oip{\hat{B}&#39;\Psi}{\hat{B}&#39;\Psi}}\geq|\oip{\hat{A}&#39;\Psi}{\hat{B}&#39;\Psi}|\]</span>
and so, conclusively, <span
class="math display">\[\Delta\hat{A}\Delta\hat{B}=\sqrt{(\hat{A}&#39;\Psi,\hat{A}&#39;\Psi)}\sqrt{(\hat{B}&#39;\Psi,\hat{B}&#39;\Psi)}\geq|\oip{\hat{A}&#39;\Psi}{\hat{B}&#39;\Psi}|\geq\frac{1}{2}|\oip{\Psi}{[\hat{A},\hat{B}]\Psi}|\]</span>
so <span
class="math display">\[\Delta\hat{A}\Delta\hat{B}\geq\frac{1}{2}|\oip{\Psi}{[\hat{A},\hat{B}]\Psi}|.\]</span>
This proves Heisenberg’s Uncertainty Principle. <span
class="math inline">\(\square\)</span><br />
<br />
This general form we have above is still difficult to interpret, but if
we consider a few examples we will realise this is a very important
result. One of the most famous iterations comes with considering simply
the two central operators of quantum mechanics: the position and
momentum operators, which we have not yet introduced but will for now
just use for calculation purposes. We can calculate the commutator:
<span class="math display">\[\begin{aligned}
&amp;[\hat{X},\hat{P}]=\hat{X}\hat{P}-\hat{P}\hat{X}\\
\Rightarrow\:\:&amp;[\hat{X},\hat{P}]\Psi(x)=-xi\hbar\frac{\partial}{\partial
x}\Psi(x)--i\hbar\frac{\partial}{\partial x}\biggl(x\Psi(x)\biggr)\\
\Rightarrow\:\:&amp;[\hat{X},\hat{P}]\Psi(x)=-i\hbar x\frac{\partial
\Psi}{\partial
x}--i\hbar\biggl[\frac{dx}{dx}\Psi(x)+x\frac{\partial\Psi}{\partial
x}\biggr]\\
\Rightarrow\:\:&amp;[\hat{X},\hat{P}]\Psi(x)=-i\hbar\biggl[x\frac{\partial\Psi}{\partial
x}-\Psi(x)-x\frac{\partial\Psi}{\partial x}\biggr]\\
\Rightarrow\:\:&amp;[\hat{X},\hat{P}]\Psi(x)=i\hbar\Psi(x)\\
\Rightarrow\:\:&amp;[\hat{X},\hat{P}]\equiv i\hbar.
\end{aligned}\]</span> After this, if we plug this into the Generalised
Uncertainty principle and assume that the wavefunction is normalised,
<span
class="math display">\[\Delta{\hat{X}}\Delta{\hat{P}}\geq\frac{1}{2}|\oip{\Psi}{i\hbar\Psi}|
\Rightarrow
\Delta{\hat{X}}\Delta{\hat{P}}\geq\frac{1}{2}|i\hbar\oip{\Psi}{\Psi}|=\frac{1}{2}|i\hbar|=\frac{1}{2}\sqrt{-i\hbar\times
i\hbar}=\frac{\hbar}{2}.\]</span> The key end result is that <span
class="math display">\[\Delta{\hat{X}}\Delta{\hat{P}}\geq\frac{\hbar}{2}.\]</span>
This is the most well known case of the Uncertainty Principle in action,
but we can see that the Generalised Uncertainty Principle can be applied
more broadly than just to the two observables of position and
momentum.<br />
<br />
Returning to our considerations of the physical results of trying to
measure two incompatible observables, it is clear how bizarre this
result is. Consider if we have just made a measurement for the position
of a particle. Then we have forced its wavefunction into a position
eigenstate and therefore we can say that the uncertainty in the position
is now <span class="math inline">\(0\)</span>: we know the successive
measurement must yield the same position value with probability 1.
However, if we plug in <span
class="math inline">\(\Delta{\hat{X}}\)</span> into the Uncertainty
Principle we get <span
class="math display">\[0\times\Delta\hat{P}\geq\frac{\hbar}{2}\]</span>
which implies somehow that the uncertainty in momentum must be
infinite!<br />
<br />
Thus, Heisenberg’s Uncertainty Principle tells us that if we know the
value of the position with certainty we are completely have infinite
uncertainty in momentum. The relationship works both ways so the same
applies for the momentum: if we know the momentum of a particle then we
necessarily have infinite uncertainty in the position of the particle
and we have not a clue where it is. This is undoubtedly one of the most
anti-classical results in quantum mechanics, and yet it results
beautifully from the mathematics we have defined (and has never been
experimentally refuted). If nothing else, it should now be clear that
the mathematical manipulations of quantum mechanics are rich and
impactful.<br />
<br />
The same is manifested, of course, in the Stern-Gerlach experiment. By
knowing <span class="math inline">\(x\)</span> spin, we had infinite
uncertainty in <span class="math inline">\(y\)</span> spin- with
absolutely no way to tell if an electron would be up or down spin. By
knowing the <span class="math inline">\(y\)</span> spin, we had infinite
uncertainty in the <span class="math inline">\(x\)</span> spin. This is
one example of an experimental verification of the Heisenberg
Uncertainty Principle.<br />
<br />
</p>
<h2 id="formulation-of-observable-operators">Formulation of Observable
Operators</h2>
<p>We have discussed in Chapter 4 the fact that the specific functional
form of an operator, just like the specific expansion of a state vector,
depends on the basis we are working on. Nevertheless, we would like to
ask the question of how to form the observable operator for a given
physical observable. Otherwise, our discussions above on Compatibility
and Incompatibility, specifically via the study of commutation
relations, would be completely useless, as we would never be able to
specify the commutator at all!</p>
<h3 id="diracs-canonical-commutation-relation">Dirac’s Canonical
Commutation Relation</h3>
<p>Very early on in classical mechanics, it was already established that
two observables, position, <span class="math inline">\(x\)</span> and
momentum, <span class="math inline">\(p\)</span>, are enough to
completely specify the state of a single body. We will not concern
ourselves with why that is true, but the same logic carries over to
quantum mechanics. Position and momentum are, it turns out, the only two
operators we need to generate any new observable operator, at least for
observables which have classical counterparts.<br />
<br />
The form of the position and momentum operators, in position space, are:
<span class="math display">\[\hat{X}\psi(x) = x\psi(x)\]</span> and
<span class="math display">\[\hat{P}\psi(x) = -i\hbar
\frac{\partial}{\partial x}\psi(x)\]</span> There are a few things to
note with these forms:</p>
<ol>
<li><p>Note that we use <span class="math inline">\(\psi(x)\)</span>
instead of the usual notation for the general state vector, <span
class="math inline">\(\Psi\)</span>. This is because we are working in
position space, so the position/momentum operators in the position space
must act on the position space expansion <span
class="math inline">\(\psi(x)\)</span> of <span
class="math inline">\(\Psi\)</span>.</p></li>
<li><p>The position space expansion, of course, can be written as <span
class="math inline">\(\psi(x)\)</span> since we explicitly defined it as
the map from basis vectors to the components of the state vector in
those basis directions. Thus, everything depends on an input eigenstate
of <span class="math inline">\(\hat{X}\)</span>; hence, we use <span
class="math inline">\(x\)</span> to denote this.</p></li>
<li><p>These forms would not be the same in, for example, momentum
space! The reason why we use the position space form is because, as
aforementioned, the majority of quantum problems are solved in position
space.</p></li>
</ol>
<p>How do we know these forms? Are they postulates? The answer is that
they are <em>derived</em> from a postulate. The postulate which really
generates these forms is Dirac’s Canonical Commutation Relation:<br />
<br />
<strong><u>Dirac’s Canonical Commutation Relation</u></strong><br />
<br />
<span class="math display">\[[\hat{X},\hat{P}]=i\hbar\]</span> where
<span class="math inline">\(i\hbar\)</span> is the notation for the
scalar <span class="math inline">\(i\hbar\)</span> multiplying the
identity operator.<br />
<br />
We already quoted this commutation relation, when we plugged it into the
Heisenberg Uncertainty Principle. Here, the reader understands that it
is a postulate. However, this simple postulate remarkably generates the
forms of nearly all observable operators!<br />
<br />
Indeed, from this seemingly small postulate, we can <em>deduce</em> the
position space (and momentum space) forms of the position operator <span
class="math inline">\(\hat{X}\)</span> and <span
class="math inline">\(\hat{P}\)</span> shown above. The full derivation
will come in Chapter 8, since we require the tools developed there to
handle continuous observables, but for now we can take the position
space form of the operators for granted.<br />
<br />
With this in mind, we can introduce the next Postulate, which tells us
how to form the observable operator of any observable, within a given
basis.</p>
<h3 id="formation-of-observable-operators">Formation of Observable
Operators</h3>
<p><strong><u>Postulate 4: The Formation of Observable
Operators</u></strong><br />
<br />
The two canonical operators in quantum mechanics, expressed in position
space, are the position operator: <span
class="math display">\[\hat{X}\Psi=x\Psi\]</span> and the momentum
operator: <span
class="math display">\[\hat{P}\Psi=-i\hbar\frac{\partial}{\partial
x}\Psi.\]</span> which can be both shown to be Hermitian. To form any
other physical observable operator, express the classical observable in
terms of the classical variables of <span
class="math inline">\(x\)</span> (position) and <span
class="math inline">\(p\)</span> (momentum), and replace the <span
class="math inline">\(x\)</span> terms with the operator <span
class="math inline">\(\hat{X}\)</span> and the <span
class="math inline">\(p\)</span> terms with the operator <span
class="math inline">\(\hat{P}\)</span>. Note that the position operator
and momentum operator are here one dimensional: if instead we were
considering position and momentum in three directions then all we would
do would be to replace the <span class="math inline">\(x\)</span> with
the <span class="math inline">\(y\)</span> and <span
class="math inline">\(z\)</span> variables for the <span
class="math inline">\(y\)</span> and <span
class="math inline">\(z\)</span> directional operators instead.
Generalising up physical dimensions (as in, position dimensions) is only
marginally more complicated because we have more terms to consider, and
otherwise this rationale stays the same and everything is
straightforward. Let us, to punch this in, consider the kinetic energy
operator, which will become very useful. Note again that everything is
happening in position space, or things would look quite different in
another space with a different eigenbasis.</p>
<h4 id="kinetic-energy-operator">Kinetic Energy Operator</h4>
<p>The classical formula for kinetic energy is of course <span
class="math display">\[KE=\frac{1}{2}mv^2.\]</span> We want this in
terms of position and momentum. It is important that mass is treated as
a constant so does not interfere in this as a separate observable. The
kinetic energy formula expressed in momentum and position is <span
class="math display">\[KE=\frac{1}{2}mv^2=\biggl(\frac{m}{2m}\biggr)mv^2=\frac{m^2v^2}{2m}\]</span>
which is, <span class="math display">\[KE=\frac{p^2}{2m}\]</span> where
position does not appear in this particular observable expression, which
is completely fine. Then, by the postulate, all we need to do is to
replace the classical variable <span class="math inline">\(p\)</span>
with the momentum operator: <span
class="math display">\[KE=\frac{p^2}{2m}\duac
\hat{KE}=\frac{\hat{P}^2}{2m}.\]</span> The notation <span
class="math inline">\(\hat{KE}\)</span> looks foolish and so convention
uses <span class="math inline">\(\hat{T}\)</span> instead. The
expression <span class="math inline">\(\hat{P}^2\)</span>, we know,
means applying the same momentum operator twice.<br />
<br />
Therefore, in position space, where the momentum operator is <span
class="math display">\[\hat{P}\Psi=-i\hbar\frac{\partial}{\partial
x}\Psi,\]</span> we get <span
class="math display">\[\hat{T}\Psi=\frac{\hat{P}^2}{2m}\Psi=-\frac{i\hbar}{2m}\biggl(\frac{\partial}{\partial
x}\biggl(-i\hbar\frac{\partial\Psi}{\partial x}\biggr)\biggr)\]</span>
which is, <span
class="math display">\[\hat{T}{\Psi}=\frac{(i\hbar)^2}{2m}\frac{\partial^2
\Psi}{\partial x^2}=-\frac{\hbar^2}{2m}\frac{\partial^2 \Psi}{\partial
x^2}.\]</span> Thus we are done, and have the position space form of the
kinetic operator: <span
class="math display">\[\hat{T}\Psi=-\frac{\hbar^2}{2m}\frac{\partial
\Psi}{\partial x^2}.\]</span></p>
<h3 id="mass-and-time">Mass and Time</h3>
<p>There is a final note to make, on mass and time. Both of these are
not treated as observables in quantum mechanics. This makes intuitive
sense for time: in experiments we would measure the duration of an
event, but this is first of all not something which pertains to the
state problem but more importantly not something we expect to involve
probability. The time at which we are measuring the time obviously
should not be probabilistic; it is therefore treated more like an
underlying variable just like the space of the universe.<br />
<br />
With mass, the complete justification is more nuanced. It turns out that
particle physics shows the existence of so-called “fundamental
particles", and that everything is made up of these particles. Then, we
create a notion of mass simply based on the “quantum number" of those
particles: which turns out to be impossible to change, hence the idea of
being ‘fundamental’. Since mass is built up concretely from this bedrock
of fundamental properties, then, it is not subject to the probabilistic
superpositions and uncertainties of other observables. Hence, it may
also be treated as a constant in a given stationary equation.<br />
<br />
The best thing to do, then, is to treat <span
class="math inline">\(m\)</span> as a constant and <span
class="math inline">\(t\)</span> as a varying but non-probabilistic
parameter. In both cases, they are not really observables and thus do
not require an observable operator to be linked to them.</p>
<h2 id="summary">Summary</h2>
<p>In this chapter, we finished addressing all the uniquely quantum
behaviour the Stern-Gerlach experiment threw at us. We proved the
incredible Heisenberg Uncertainty Principle, as well as the less
explosive but equally insightful Compatibility Theorem, and showed that
the mathematical manipulations of quantum mechanics, specifically herein
with respect to the commutation relations between two observable
operators, can really yield very rich conceptual and algebraic
connections. Finally, we also explicitly showed how to construct
observable operators without needing to postulate the form of every
single one, even though this story is still to be completed more
carefully in Chapter 7 and Chapter 8.</p>
<hr>
<div style="text-align: center; font-size: 1.2em; padding-top: 20px;">
    <a href='4.html'>&larr; Previous Chapter</a> &nbsp;&nbsp; | &nbsp;&nbsp; <a href='6.html'>Next Chapter &rarr;</a>
</div>
</body>
</html>
