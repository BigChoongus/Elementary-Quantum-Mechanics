<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>8</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="style.css" />
  <script>
      window.MathJax = {
        loader: { load: ['[tex]/newcommand'] },
        tex: {
          packages: { '[+]': ['base', 'ams', 'newcommand'] },
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']]
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
      };
      </script>
      <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
    $$
    \newcommand{\Answer}{\begin{tcolorbox}}
    \newcommand{\Answerend}{\end{tcolorbox}}
    \newcommand{\ket}[1]{|#1\rangle}
    \newcommand{\bra}[1]{\langle#1|}
    \newcommand{\ip}[2]{\langle#1|#2\rangle}
    \newcommand{\bip}[2]{\left\langle#1\middle|#2\right\rangle}
    \newcommand{\qexp}[1]{\langle#1\rangle}
    \newcommand{\apos}[1]{``#1"}
    \newcommand{\sapos}[1]{`#1'}
    \newcommand{\elec}{e^{-}}
    \newcommand{\uspin}{(\uparrow)}
    \newcommand{\dspin}{(\downarrow)}
    \newcommand{\lspin}{(\leftarrow)}
    \newcommand{\rspin}{(\rightarrow)}
    \newcommand{\ulspin}{(\uparrow\leftarrow)}
    \newcommand{\urspin}{(\uparrow\rightarrow)}
    \newcommand{\dlspin}{(\downarrow\leftarrow)}
    \newcommand{\drspin}{(\downarrow\rightarrow)}
    \newcommand{\R}{\mathbb{R}}
    \newcommand{\stab}{\:\:}
    \newcommand{\mtab}{\:\:\:}
    \newcommand{\btab}{\:\:\:}
    \newcommand{\imp}{\Rightarrow}
    \newcommand{\doubimp}{\Leftrightarrow}
    \newcommand{\setof}[1]{\{#1\}}
    \newcommand{\infint}{\int_{-\infty}^{\infty}}
    \newcommand{\trans}[1]{\mathcal{T}(#1)}
    \newcommand{\dd}[2]{\delta(#1-#2)}
    \newcommand{\ipbig}[2]{\langle#1|#2\rangle}
    \newcommand{\talpha}{\tilde{\alpha}}
    \newcommand{\op}[2]{|#1\rangle\langle#2|}
    \newcommand{\sop}[1]{|#1\rangle\langle#1|}
    \newcommand{\prop}[2]{\mathcal{U}(#1,#2)}
    \newcommand{\propdagg}[2]{\mathcal{U}^{\dagger}(#1,#2)}
    \newcommand{\sip}[1]{\langle#1|#1\rangle}
    \newcommand{\optrip}[3]{\langle#1|\hat{#2}|#3\rangle}
    \newcommand{\nhoptrip}[3]{\langle#1|{#2}|#3\rangle}
    \newcommand{\northexp}[2]{\sum_{i=1}^{n}|#2\rangle\langle#2|#1\rangle}
    \newcommand{\orthexp}[4]{\sum_{#3=1}^#4|#2\rangle\langle#2|#1\rangle}
    \newcommand{\schrodeq}{i\hbar\frac{\partial \Psi(x,t)}{\partial t}=\hat{H}\Psi(x,t)}
    \newcommand{\nd}[2]{\frac{d#1}{d #2}}
    \newcommand{\snd}[2]{\frac{d^{2}#1}{d#2^2}}
    \newcommand{\pd}[2]{\frac{\partial#1}{\partial #2}}
    \newcommand{\spd}[2]{\frac{\partial^{2}#1}{\partial #2^2}}
    \newcommand{\duac}{\leftrightarrow}
    \newcommand{\oip}[2]{\left(#1,#2\right)}
    \newcommand{\obip}[2]{\left(#1,#2\right)}
    $$
<h1 id="problems-in-quantum-mechanics">Problems in Quantum
Mechanics</h1>
<p>This chapter, and the next, will practice all the concepts we have
learnt with physical problems. The algebraic labour involved will be
extensive, but how could it be otherwise? I have kept all the solutions
in Dirac notation, because this is conventional and because manipulation
with Dirac notation is more powerful and fruitful.</p>
<h2 id="the-propagator">The Propagator</h2>
<p>We have mentioned how one can use energy eigenstates to conveniently
find solutions for the Schrödinger equation. However, beyond this
algebraic method there is another method, the method of the propagator,
which is used ubiquitously by those more advanced in quantum mechanics.
In this book, it might seem even at the end counterintuitive to have
learnt both the energy eigenstate method and the propagator method, but
the crucial point is that for more difficult problems only the latter is
viable; while we might not have the full mathematical tools to realise
how useful it is, no mature treatment of quantum mechanics is complete
without it, and we can still use it for the simpler problems we cover
even if its formulation might seem to contribute nothing for these basic
examples. It is also, mathematics aside, a conceptually valuable thing
to study even at an expository level.<br />
<br />
At time <span class="math inline">\(t_{0}\)</span> the state must be
able to be represented by a ket in the ket space. At any other time
<span class="math inline">\(t\)</span> the state must also be able to be
represented by a ket in the ket space. One therefore might be led to
consider whether there is an operator which governs the mapping of one
state ket to another state ket given some input time <span
class="math inline">\(t-t_{0}\)</span> which has passed.<br />
<br />
There is, and it is called the propagator (or time evolution operator).
More importantly, the operator turns out to be the same over all time
<strong>given the same Hamiltonian</strong> (i.e, given the system is
not perturbed). We can try to formulate it, as we know some conditions
we expect to be fulfilled.<br />
<br />
Denote the operator <span class="math inline">\(\prop{t}{t_{0}}\)</span>
to be the propagator which carries a state ket from time <span
class="math inline">\(t_{0}\)</span> to a ket at time <span
class="math inline">\(t\)</span>. The first condition we expect the
propagator to satisfy is the property of composition: <span
class="math display">\[\forall\: t_{0}\leq t_{1} \leq t_{2}, \btab
\prop{t_{2}}{t_{0}}=\prop{t_{2}}{t_{1}}\prop{t_{1}}{t_{0}}.\]</span>
This is because the propagator of a system carrying a ket from <span
class="math inline">\(t_{0}\)</span> to <span
class="math inline">\(t_{1}\)</span> to <span
class="math inline">\(t_{2}\)</span> should be an equivalent
transformation to carrying a ket from <span
class="math inline">\(t_{0}\)</span> to <span
class="math inline">\(t_{2}\)</span> directly since the start and end
kets are the same.<br />
<br />
The second condition is subtle but important. Take a ket <span
class="math inline">\(\ket{\Psi,{t_{0}}}\)</span>, We expect that for a
proper physical ket it is normalised, so that the total sum of
probabilities is always <span class="math inline">\(1\)</span> for any
measurements of a given observable. Now, if we consider <span
class="math display">\[\prop{t}{t_{0}}\ket{\Psi,{t_{0}}}:=\ket{\Psi,{t}},\]</span>
then the norm at time <span class="math inline">\(t\)</span> of the
state ket becomes <span class="math display">\[\ip{\Psi,{t}}{\Psi,{t}}=
\bra{\Psi,{t_{0}}}\:{\propdagg{t}{t_{0}}\prop{t}{t_{0}}}\:\ket{\Psi,{t_{0}}}.\]</span>
We expect that the ket at times IS still normalised, or the sums of
probabilities for measurements will not equal <span
class="math inline">\(1\)</span>. Therefore we have <span
class="math display">\[\sip{\Psi,t_{0}}=\sip{\Psi,t}=1=\bra{\Psi,{t_{0}}}\:{\propdagg{t}{t_{0}}\prop{t}{t_{0}}}\:\ket{\Psi,{t_{0}}}.\]</span>
This means we must have: <span
class="math display">\[{\propdagg{t}{t_{0}}\prop{t}{t_{0}}}=1.\]</span>
Otherwise stated, the propagator is unitary! In fact this is a
requirement for operators which map a physical state onto another
physical state, due to the necessity of <strong>conservation of
probability</strong>– really, conservation of normalisation–, which
unitary operators always fulfil because they preserve the norm of any
ket they act on.<br />
<br />
Finally, we expect that <span
class="math display">\[\lim_{dt\to0}\prop{t_{0}+dt}{t_{0}}=1\]</span>
(the identity operator), due to the continuity of time. Now, we do know
that the Schrödinger Equation must still apply- in other words, we know
that <span class="math display">\[i\hbar\frac{\partial}{\partial
t}\ket{\Psi,{t}}=\hat{H}\ket{\Psi,{t}}.\]</span> Assume the state <span
class="math inline">\(\ket{\Psi,t_{0}}\)</span> was a precedent state to
<span class="math inline">\(\ket{\Psi,t}\)</span>. We therefore have
<span class="math display">\[i\hbar\frac{\partial}{\partial
t}\prop{t}{t_{0}}\ket{\Psi,{t_{0}}}=\hat{H}\prop{t}{t_{0}}\ket{\Psi,{t_{0}}}\]</span>
so we can equate the two operators since it holds true for any <span
class="math inline">\(\ket{\Psi,t_{0}}\)</span>: <span
class="math display">\[i\hbar\frac{\partial}{\partial
t}\prop{t}{t_{0}}=\hat{H}\prop{t}{t_{0}}.\]</span> This is called the
Schrödinger Equation for the time evolution operator.<br />
<br />
We would like there to be a very simple way to find the propagator,
because having an explicit representation of the propagator is
sufficient to solving the time evolution problem (we can apply it to any
initial state <span class="math inline">\(\ket{\Psi,t_{0}}\)</span>). We
can try to induce its form through looking at equations we know must
hold, since we understand its usage and what properties it must
have.<br />
<br />
The reader might be relieved to know our starting point is the energy
eigenfunction method of solving the Schrödinger Equation, which is not
incorrect at all (we derived it very soundly from the Schödinger
Equation, and the reader may go back to review that proof if they need
do so before continuing) and need not be discarded. In our function
formulation, we had <span
class="math display">\[\psi_{t}^{(n)}:=e^{-iE_{n}t/\hbar}\varepsilon_{n}\]</span>
as the stationary states of any given system- in other words, where time
evolution does not change the states at all. In our Dirac notation this
is <span
class="math display">\[\ket{\Psi_{n},t}=e^{-iE_{n}t/\hbar}\ket{E_{n}}\]</span>
where we have labelled kets by their eigenvalues as is customary. The
derivation <span
class="math display">\[\Psi_{t}=\sum_{n}(\varepsilon_{n},\Psi_{0})\psi_{t}^{(n)}\]</span>
was made where <span class="math inline">\(\Psi_{t}\)</span> is any
arbitrary state at time <span class="math inline">\(t\)</span> and <span
class="math inline">\(\Psi_{0}\)</span> was the state at time <span
class="math inline">\(0\)</span>. We translate this to Dirac notation as
well: <span class="math display">\[\ket{\Psi,
t}=\sum_{n}\ket{\Psi_{n}}\ip{E_{n}}{\Psi,0}=\sum_{n}e^{-iE_{n}t/\hbar}\ket{E_{n}}\ip{E_{n}}{\Psi,0}.\]</span>
However, this allows us to induce the form of the propagator: <span
class="math display">\[\ket{\Psi,
t}=\sum_{n}e^{-iE_{n}t/\hbar}\ket{E_{n}}\ip{E_{n}}{\Psi,0}=\biggl(\sum_{n}e^{-iE_{n}t/\hbar}\ket{E_{n}}\bra{E_{n}}\biggr)\ket{\Psi,0}\]</span>
and <span
class="math display">\[\ket{\Psi,t}=\prop{t}{0}\ket{\Psi,0}\]</span> so
therefore <span
class="math display">\[\prop{t}{0}=\sum_{n}e^{-iE_{n}t/\hbar}\ket{E_{n}}\bra{E_{n}}\stab.\]</span>
This form of the propagator of course applies when the energy eigenkets
are discrete: a phenomenon which does often occur in problems, as we
will see shortly. It should be noted that <span
class="math inline">\(e^{-iE_{n}t/\hbar}\)</span> is not a constant, as
its value depends on the eigenvalue <span
class="math inline">\(E_{n}\)</span> which varies over the different
indexes <span class="math inline">\(n\)</span>, so trying to pull it out
of the sum term is invalid. Furthermore, the continuous analog (for
continuous energies, which also occur) should be equally clear, as we
can simply take an integral: <span
class="math display">\[\prop{t}{0}=\infint
e^{-iE_{n}t/\hbar}\ket{E_{n}}\bra{E_{n}}\,dn.\]</span> In reality, using
<span class="math inline">\(n\)</span> as an index for a continuously
varying entity, and integrating with respect to that contrived <span
class="math inline">\(n\)</span>, is somewhat hideous. However, the idea
is that we integrate over the changing values of <span
class="math inline">\(E_{n}\)</span>, which correspond to the labelled
kets <span class="math inline">\(\ket{E_{n}}\)</span>. Finally, we will
not consider time varying Hamiltonians as they are extremely
difficult.</p>
<h3 id="the-free-particle-propagator">The Free Particle Propagator</h3>
<p>We can now formulate the propagator for the free particle, whose
solution we studied without a propagator already in chapter 5. The
energy eigenkets of the Hamiltonian, which commutes with the momentum
operator, are of the form <span
class="math display">\[\ket{E_{n};+}=\ket{p=\sqrt{2mE_{n}}\:}\]</span>
and <span
class="math display">\[\ket{E_{n};-}=\ket{p=-\sqrt{2mE_{n}}\:}.\]</span>
The <span class="math inline">\(+\)</span> and <span
class="math inline">\(-\)</span> inner labels summarise the fact that
these energy eigenvalues are degenerate: they apply to two distinct
eigenkets- but with different momenta corresponding to them (the reader
should probably revise the section on the Free Particle to recall this).
We therefore label the eigenkets by their nondegenerate momenta instead
of using the natural <span class="math inline">\(E\)</span> label. This
means for the propagator: <span
class="math display">\[\prop{t}{0}=\infint
e^{-iE_{n}t/\hbar}\ket{E_{n}}\bra{E_{n}}\,dn\]</span> we can write it
for the free particle as <span
class="math display">\[\prop{t}{0}=\infint
e^{-ip^{2}t/2m\hbar}\ket{p}\bra{p}\,dp.\]</span> Note that, while we
before were unscrupulously using an index <span
class="math inline">\(n\)</span> to vary over the continuous eigenkets
since it made the analog from discrete to continuous clearer, we have
replaced that with the continuous index <span
class="math inline">\(p\)</span>, which makes far more sense in any
case. The term <span class="math inline">\(p^2/2m\)</span> has replaced
the term <span class="math inline">\(E_{n}\)</span> since it is the
energy value corresponding to the eigenstate with eigenmomentum <span
class="math inline">\(p\)</span>.<br />
<br />
We now may choose a basis to work in to evaluate the propagator
elements. Evaluating the position space matrix elements <span
class="math display">\[\bra{x}\prop{t}{0}\ket{x_{0}}\]</span> makes more
sense than evaluating the momentum space matrix elements, <span
class="math display">\[\bra{p}{\prop{t}{0}}\ket{p&#39;}\]</span> since
the latter clearly is going to involve delta functions and we might
prefer to avoid this for an operator we want to readily apply. In the
position space the elements are <span
class="math display">\[\bra{x}\prop{t}{0}\ket{x_{0}}=\infint
e^{-ip^{2}t/2m\hbar}\ip{x}{p}\ip{p}{x_{0}}\,dp\]</span> and this can be
readily written in terms of the position space momentum eigenfunctions:
<span class="math display">\[\bra{x}\prop{t}{0}\ket{x_{0}}=\infint
e^{-ip^{2}t/2m\hbar} \psi_{p}(x)\psi^{\ast}_{p}(x_{0})\,dp.\]</span> The
eigenfunctions are given by <span
class="math display">\[\psi_{p}(x)=\frac{1}{\sqrt{2\pi\hbar}}e^{ipx}\]</span>
so the above is <span class="math display">\[\begin{aligned}
\bra{x}\prop{t}{0}\ket{x_{0}}&amp;=\infint e^{-ip^{2}t/2m\hbar}
\psi_{p}(x)\psi^{\ast}_{p}(x_{0})\,dp\\
\bra{x}\prop{t}{0}\ket{x_{0}}&amp;=\infint e^{-ip^{2}t/2m\hbar}
\biggl(\frac{1}{\sqrt{2\pi\hbar}}e^{ipx/\hbar}\biggr)\biggl(\frac{1}{\sqrt{2\pi\hbar}}e^{-ipx_{0}/\hbar}\biggr)\,dp\\
\bra{x}\prop{t}{0}\ket{x_{0}}&amp;=\frac{1}{2\pi\hbar}\infint
e^{-ip^{2}t/2m\hbar} e^{ip(x-x_{0})/\hbar}\,dp\\
\bra{x}\prop{t}{0}\ket{x_{0}}&amp;=\frac{1}{2\pi\hbar}\infint
e^{-(it/2m\hbar)p^{2}+(i(x-x_{0})/\hbar)p}\,dp\\
\end{aligned}\]</span> While to the inexperienced mathematician this
integral is not straightforward, in the wider scope of things this
integral is in fact trivial, because of the relatively simple fact we
can quote that <span class="math display">\[\infint
e^{-ax^2+bx}\,dx=e^{b^2/4a}\sqrt{\frac{\pi}{a}}.\]</span> Plugging in
<span class="math inline">\(a:=it/2m\hbar\)</span> and <span
class="math inline">\(b:=i(x-x_{0})/\hbar\)</span>, and changing the
integral to be with respect to <span class="math inline">\(p\)</span>
rather than <span class="math inline">\(x\)</span>, we get: <span
class="math display">\[\begin{aligned}
\bra{x}\prop{t}{0}\ket{x_{0}}&amp;=\frac{1}{2\pi\hbar}\infint
e^{-(it/2m\hbar)p^{2}+(i(x-x_{0})/\hbar)p}\,dp\\
\bra{x}\prop{t}{0}\ket{x_{0}}&amp;=\frac{1}{2\pi\hbar}e^{i(x-x_{0})/\hbar)^2/4(it/2m\hbar)}\sqrt{\frac{\pi}{it/2m\hbar}}\\
\bra{x}\prop{t}{0}\ket{x_{0}}&amp;=\biggl(\frac{1}{2\pi\hbar}\biggr)e^{-m(x-x_{0})/2it\hbar}\sqrt{\frac{2m\pi\hbar}{it}}\\
\bra{x}\prop{t}{0}\ket{x_{0}}&amp;=\sqrt{\frac{m}{2i\pi\hbar
t}}\:e^{im(x-x_{0})/2\hbar t}\stab.
\end{aligned}\]</span> It appears laborious, but actually requires
neither advanced mathematical skills nor obscure mathematical facts to
evaluate. The benefit is now we can plug in any state vector <span
class="math inline">\(\Psi\)</span> and we will have a perfect
understanding of how it will evolve with time. Thus such a process (with
proof of the momentum energy relationship) would be sufficient to solve
the problem of the free particle.<br />
<br />
To prepare for the next section, we will look at a small modification of
the free particle question, and see that it vastly changes the result we
get so far as to even discretise the energy spectrum. We will from now
onwards continue to use the propagator, as it is ubiquitous in
post-expository quantum mechanics texts.</p>
<h2 id="particle-on-an-ellipse">Particle on an Ellipse</h2>
<p>Let’s start with an interesting modification to the free particle
problem. Consider the ellipse below (which could be a circle– the
difference does not here matter): <span class="math display">\[\\
\\
\\
\]</span></p>
<div class="center">

</div>
<p><br />
Say that a free particle <span
class="math inline">\(\mathfrak{p}\)</span> is confined to be on that
ellipse at all times. Consider position <span
class="math inline">\(x\)</span> as the particle’s starting point, and
imagine the particle moving anticlockwise around the ellipse infinitely
many times. Now we can draw a helpful visual representation of the
linear distance <span class="math inline">\(\mathfrak{p}\)</span> has
travelled:</p>
<div class="center">

</div>
<p><br />
...and so on infinitely many times. Take L to be the perimeter of the
ellipse. Then it is clear that after moving in a perfect cycle for the
length of one perimeter of the ellipse the particle will end back at
position <span class="math inline">\(x\)</span> once more. In other
words, we write: <span class="math display">\[x \sim x+L\]</span> This
means that the position <span class="math inline">\(x\)</span> is
equivalent to position <span class="math inline">\(x+L\)</span>, and the
relation carries on until infinity as <span
class="math inline">\(x+L\sim x+2L\)</span> and so on.<br />
<br />
Now, considering the the system using Schrodinger’s equation, we expect
<span class="math display">\[\psi(x) = \psi(x+L)\]</span> for all
positions <span class="math inline">\(x\)</span>. Now, the free particle
time independent Schrödinger Equation is familiar to us: <span
class="math display">\[\hat{H}\Psi = \frac{\hat{P}^2}{2m}\Psi =
E\Psi\]</span> and we also know <span
class="math inline">\(\psi(x)=\psi(x+L)\)</span>. Note that the <span
class="math inline">\(\psi(x)\)</span> indicates we are working in
position space, which makes perfect sense considering the interesting
cyclic behaviour of varying position along the ellipse meaning we want
<span class="math inline">\(x\)</span> to be the central changing
variable.<br />
<br />
We can come to a solution for the particle on an ellipse quite
organically. We first note that due to the form of the Hamiltonian
energy and momentum must still be compatible observables, since neither
operators are changed by the periodic behaviour bestowed by the
elliptical setup. Therefore, the energy eigenkets we derived before are
still correct: <span
class="math display">\[\ket{E;P^{+}}=\ket{p=\sqrt{2mE}\:}, \btab
\ket{E;P^{-}}=\ket{p=-\sqrt{2mE}\:}\]</span> for each <span
class="math inline">\(E\)</span>. We again choose the nondegenerate
momentum eigenkets to represent the energy spectrum, though we do not
know whether it is discrete or continuous yet. The solution comes from
noting facts we already know. The momentum eigenkets, which are also
energy eigenkets, correspond to: <span
class="math display">\[\ket{p}\duac\frac{1}{\sqrt{2\pi\hbar}}e^{ipx/\hbar}\]</span>
and this seems innocuous until we remember the boundary condition: <span
class="math display">\[\Psi(x)=\Psi(x+L)\]</span> That is, due to there
being no external potential, we do not expect the wavefunction to change
when it travels a length of the perimeter of the ellipse and returns to
the same position. We therefore expect the same bounds to apply to the
energy eigenkets- and similarly, the momentum eigenkets. However, this
means we expect: <span class="math display">\[\ket{p;
x=x}\duac\frac{1}{\sqrt{2\pi\hbar}}e^{ipx/\hbar}= \ket{p;
x=x+L}\duac\frac{1}{\sqrt{2\pi\hbar}}e^{ip(x+L)/\hbar}.\]</span> We then
expect <span
class="math display">\[\frac{1}{\sqrt{2\pi\hbar}}e^{ipx/\hbar}=\frac{1}{\sqrt{2\pi\hbar}}e^{ip(x+L)/\hbar}
\implies e^{i(p/\hbar)x}=e^{i(p/\hbar)x}e^{i(p/\hbar)L}\]</span> and so
we must have <span class="math display">\[e^{i(p/\hbar)L}=1\]</span>
This is rather dramatic. By Euler’s equation we get: <span
class="math display">\[\begin{aligned}
e^{ix} = \cos(x) + i\sin(x)
\end{aligned}\]</span><br />
Therefore <span class="math display">\[\begin{aligned}
e^{i(p/\hbar)L} = 1 \Rightarrow\:\: \cos((p/\hbar)L) +
i\sin((p/\hbar)L)=1
\end{aligned}\]</span><br />
We need to get rid of the sine function part which is multiplied by an
imaginary unit, since the cosine function is real-valued, the sine
function is real valued, and <span class="math inline">\(1\)</span> is a
real number, so we must have <span
class="math inline">\(\sin((p/\hbar)L)=0\)</span> or we would get a
complex but not real left hand side and a real right hand side: a
contradiction. Then to finish we need <span
class="math inline">\(\cos{(p/\hbar)L}=1\)</span>, which means <span
class="math display">\[pL/\hbar=2n\pi, \:\:
n\in\mathbb{Z}.\]</span><br />
We see now that the above equation is quantized- indexed by the integers
<span class="math inline">\(n\)</span>. Therefore momentum <span
class="math inline">\(p\)</span> is also quantized and therefore energy
must also be quantised as the energy eigenvalues are equal to <span
class="math inline">\(p^2/2m\)</span>. Such is a very common theme in
quantum mechanics: <span class="math inline">\(\sin(n\pi) = 0\)</span>
and <span class="math inline">\(\cos{2n\pi}=1\)</span> for <span
class="math inline">\(n\in\mathbb{Z}\)</span>, which indexes by integers
<span class="math inline">\(n\)</span> when there is boundary behaviour
causing periodic recurrences. Now we can index the eigenvalues with
<span class="math inline">\(n\)</span>, and summarise that: <span
class="math display">\[\begin{aligned}
p_n= \frac{2\pi n\hbar}{L}, \:\: n\in\mathbb{Z}.
\end{aligned}\]</span> Then, the eigenenergies must be: <span
class="math display">\[E_{n}=(p_n)^2/2m=\frac{2\pi^2n^2\hbar^2}{mL^2}.\]</span>
Now we want to evaluate the new propagator for this free particle on an
ellipse. To do this we could solve the time independent Schrödinger to
find the energy eigenstates. However, we can also simply solve the
momentum eigenvalue equations, which are a bit simpler, since we already
know that <span
class="math display">\[\hat{P}\ket{\psi_{p}}=p\ket{\psi_{p}}\implies
\psi_{p}(x)=\frac{1}{\sqrt{2\pi\hbar}}e^{ipx/\hbar}.\]</span> Plugging
in the momentum eigenvalues <span class="math inline">\(p_{n}\)</span>
and indexing by <span class="math inline">\(n\)</span>, we have <span
class="math display">\[\psi_{p}^{(n)}(x)=\frac{1}{\sqrt{2\pi\hbar}}e^{2\pi
nix/L}\]</span> which are also the position space energy eigenstates
corresponding to the energy eigenvalues <span
class="math inline">\(E_{|n|}\)</span>. The propagator can then be
expressed: <span
class="math display">\[\prop{t}{0}=\sum_{n}e^{-iE_{n}t/\hbar}\ket{E_{n}}\bra{E_{n}}\]</span>
and we are working with discrete energy eigenkets so we can use this
form of the propagator as well. The position space elements should be
clear: <span class="math display">\[\begin{aligned}
\bra{x}{\prop{t}{0}}\ket{x_{0}}&amp;=\sum_{n}e^{-iE_{n}t/\hbar}\ip{x}{E_{n}}\ip{E_{n}}{x_{0}}\\
\bra{x}{\prop{t}{0}}\ket{x_{0}}&amp;=\sum_{n}e^{-iE_{n}t/\hbar}E_{n}(x)E_{n}^{\ast}(x_{0}).
\end{aligned}\]</span> Substituting in the energy eigenstates <span
class="math display">\[\bra{x}{\prop{t}{0}}\ket{x_{0}}=\sum_{n}e^{-iE_{n}t/\hbar}\biggl(\frac{1}{\sqrt{2\pi\hbar}}e^{2\pi
nix/L}\biggr)\biggl(\frac{1}{\sqrt{2\pi\hbar}}e^{-2\pi
nix_{0}/L}\biggr)\]</span> and substituting the energy eigenvalue <span
class="math inline">\(E_{n}\)</span>, <span
class="math display">\[\bra{x}{\prop{t}{0}}\ket{x_{0}}=\frac{1}{2\pi
\hbar}\sum_{n}e^{-2i\pi^{2}n^{2}\hbar t/mL^{2}}e^{2\pi nix/L}e^{-2\pi
nix_{0}/L}\]</span> simplifying, <span
class="math display">\[\bra{x}{\prop{t}{0}}\ket{x_{0}}=\frac{1}{2\pi
\hbar}\sum_{n}e^{(2\pi i n)/L[\pi n\hbar t/mL ]}.\]</span><br />
<br />
<br />
<br />
we see that the full set of solutions to Schrodinger’s Equation for a
free particle on a circle can be categorised by: <span
class="math display">\[\Psi_n(x)= Ne^{ik_n x}\]</span> where N was the
normalisation constant assumed earlier when we eliminated <span
class="math inline">\(\int_{0}^{L}\psi^\ast(x)\psi(x)\)</span>. Its
value can calculated easily: <span
class="math display">\[\begin{aligned}
&amp;\Psi_n(x)= Ne^{ik_n x}, \:\:
\int_{0}^{L}\psi_n^\ast(x)\psi_n(x)=1\\
\Rightarrow\:\: &amp;\int_{0}^{L}Ne^{ikx}Ne^{-ikx} = 1\\
\Rightarrow\:\: &amp;N^2\int_{0}^{L}1 = 1\\
\Rightarrow\:\: &amp;N^2\int\frac{d}{dx}(x+c)=1\\
\Rightarrow\:\: &amp;N^2\biggl[x+c\biggr]_{0}^{L} = 1 \Rightarrow\:\:
N^2L = 1 \Rightarrow\:\: N= \frac{1}{\sqrt{L}}
\end{aligned}\]</span><br />
Overall, we have: <span
class="math display">\[\Psi_n(x)=\frac{1}{\sqrt{L}}e^{ik_nx}\]</span><br />
and since <span class="math inline">\(k_nL=2\pi n \Rightarrow\:\:
k_n=\frac{2\pi n}{L}\)</span>, we can also write this as: <span
class="math display">\[\Psi_n(x)=\frac{1}{\sqrt{L}}e^{\frac{2\pi
nix}{L}}.\]</span> This is a normalised set of wavefunctions due to the
normalisation coefficient, but is it an orthogonal set too? We can
verify this.<br />
Furthermore, we also know that as <span
class="math inline">\(V(x)=0\)</span> then associated energies indexed
by integers <span class="math inline">\(n\)</span> are: <span
class="math display">\[E_n = \frac{\hat{p}^2}{2m} =
\frac{\hbar^2k_n^2}{2m} = \frac{\hbar^2}{2m}\left(\frac{2\pi
n}{L}\right)^2\]</span><br />
so they are <span
class="math display">\[E_n=\frac{2\pi^2\hbar^2n^2}{mL^2}\]</span><br />
Note that despite the fact <span class="math inline">\(n\)</span> can be
negative, corresponding to negative momentum, the <span
class="math inline">\(n^2\)</span> term in the equation for <span
class="math inline">\(E\)</span> ensures that <span
class="math inline">\(E &gt; 0\)</span> as we have earlier shown.
Clearly there are infinite energy eigenstates as there are infinite
integers <span class="math inline">\(n\)</span> to index <span
class="math inline">\(E_n\)</span>.<br />
<br />
However, since <span class="math inline">\(E_n\)</span> is a function of
<span class="math inline">\(n^2\)</span> it is also clear that all the
energy eigenstates for a free particle on an ellipse can correspond to
both <span class="math inline">\(\psi_n\)</span> and <span
class="math inline">\(\psi_{-n}\)</span> which both have energy <span
class="math inline">\(E_n\)</span>, save for <span
class="math inline">\(E_0\)</span>. We say that all these non-zero
energy eigenstates are degenerate: they can correspond to multiple
wavefunctions, here 2. The temptation would be to say that we have an
issue herein since that would make <span
class="math inline">\(\psi_n\)</span> and <span
class="math inline">\(\psi_{-n}\)</span> indistinguishable from the
point of view of energy: but of course we very easily know that what
distinguishes <span class="math inline">\(\psi_n\)</span> and <span
class="math inline">\(\psi_{-n}\)</span> is that they have different
momenta.</p>
<h2 id="bound-states">Bound States</h2>
<p>In the last problem, we made one modification– or really, added one
constraint– to the free particle problem, and found this discretised the
energy spectrum immediately. Physically, the constraint seems rather
significant, given that we expected the particle’s motion to loop around
in infinite cycles. Mathematically, however, it was only equivalent to
adding positionwise periodicity. There exists this question now of how
that discretisation occurred in the first place, and specifically, we
can point to a specific class of problems which will be valuable to our
understanding of this: those problems of bound states.</p>
<h4 id="a-general-discussion">A General Discussion</h4>
<p>A bound state in quantum mechanics is a state where we have the
relationship <span
class="math display">\[|x|\to\infty\implies\Psi(x)\longrightarrow
0.\]</span> That is, the wavefunction is focused on one point, which we
can call position <span class="math inline">\(0\)</span>, and the
further away we get from that point the smaller the value <span
class="math inline">\(\Psi(x)\)</span> (the probability density
corresponding to that point) is. The most basic example of this would
occur if we had some barrier which prevented or made it practically very
difficult for a particle trying to escape outside it. Of course, on a
microscopic scale we cannot speak of stone walls or physical barriers,
but we will see that barriers nevertheless can exist based on the
potential of the system. We start by introducing a fact which exists in
classical mechanics and stays valid in quantum mechanics- that a
particle cannot have energy less than the minimum value of the potential
of the system at any point. The proof is as follows: we know that the
Hamiltonian is given by the formula <span
class="math display">\[\hat{H}=\frac{\hat{P}}{2m}+V(x).\]</span> Now
pick a normalised energy eigenket <span
class="math inline">\(\psi_{E}(x)\)</span> which has energy <span
class="math inline">\(E\)</span>. We have: <span
class="math display">\[\optrip{\psi_{E}}{H}{\psi_{E}}=E\sip{\psi_{E}}=E\]</span>
but we also have <span
class="math display">\[\optrip{\psi_{E}}{H}{\psi_{E}}=\bra{\psi_{E}}{\hat{T}+V(x)}\ket{\Psi_{E}}=\optrip{\psi_{E}}{{T}}{\psi_{E}}+\bra{\psi_{E}}V(x){\ket{\Psi_{E}}}\]</span>
and for some minimum value of <span class="math inline">\(V(x)\)</span>
we have <span
class="math display">\[\optrip{\psi_{E}}{H}{\psi_{E}}=\optrip{\psi_{E}}{{T}}{\psi_{E}}+\bra{\psi_{E}}V(x){\ket{\Psi_{E}}}\geq\optrip{\psi_{E}}{{T}}{\psi_{E}}+V_{\min}\sip{\psi_{E}}\]</span>
that is, <span
class="math display">\[E\geq\optrip{\psi_{E}}{T}{\psi_{E}}+V_{\min}\]</span><br />
<br />
using the algebraic form of the momentum operator, the Schrödinger
Equation is <span
class="math display">\[-\frac{\hbar^2}{2m}\snd{\Psi}{x}+(V(x)-E)\Psi=0.\]</span>
If <span class="math inline">\(E\geq V(x)\)</span> for some point <span
class="math inline">\(x\)</span> then <span
class="math inline">\((V(x)-E)\)</span> will clearly be nonpositive.
However, at the moment <span class="math inline">\(E&lt;V(x)\)</span>,
we must get the condition that <span
class="math inline">\(V(x)-E\)</span> is positive. If we put denote this
difference as <span class="math inline">\(\Delta&gt;0\)</span>, then we
get the equation <span
class="math display">\[-\frac{\hbar^2}{2m}\snd{\Psi}{x}+\Delta\Psi=0\implies\frac{\hbar^2}{2m}\snd{\Psi}{x}=\Delta\Psi.\]</span>
This is comparable to the differential equation , whose solution leaks
out to infinity and does not fit the definition of a bound state.
Therefore in any bound state we can never have energy less than the
potential of the system; furthermore, this means that no energy
eigenstates exist whose corresponding eigenvalues are less than the
minimum value of the potential at some point.<br />
<br />
We can now see how we can create a bound state: by setting regions where
the potential is higher than the energy of the state and where therefore
the wavefunction must disappear. In particular, a region with infinite
potential must immediately have the wavefunction vanish as it cannot
have an energy greater than infinity. Let us use this to investigate a
classic introductory problem in quantum mechanics which involves a bound
state, the infinite square well.</p>
<h2 id="particle-in-an-infinite-square-well">Particle in an Infinite
Square Well</h2>
<p>Examine the following diagram: <span class="math display">\[\\
\\
\\
\]</span></p>
<div class="center">

</div>
<p>At the shaded regions the potential is defined to be infinite. But
between positions <span class="math inline">\(x=0\)</span> and <span
class="math inline">\(x=L\)</span> it is defined as <span
class="math inline">\(V(x)=0\)</span>. Due to the fact that the energy
of a particle must be greater than the potential it is experiencing, we
have two conditions that within the well it must have positive energy,
and outside its wavefunction must vanish, so the lines <span
class="math inline">\(x=0\)</span> and <span
class="math inline">\(x=L\)</span> act as hard walls which bind the
state to being between positions <span class="math inline">\(0\)</span>
and <span class="math inline">\(L\)</span>.<br />
<br />
We can list the properties of the system given by the boundary
conditions:</p>
<ol>
<li><p><span class="math inline">\(\Psi(x)\)</span> does not exist if
<span class="math inline">\(x&gt;L\)</span> or <span
class="math inline">\(x&lt;0\)</span>.</p></li>
<li><p>The new normalisation requirement for the system <span
class="math inline">\(\Psi\)</span> is <span
class="math inline">\(\sip{\Psi}=1=\int_{0}^{L}
\Psi^\ast(x)\Psi(x)\,dx\)</span>. This is because the boundary
conditions require that the probability of the wavefunction being
between <span class="math inline">\(0\)</span> and <span
class="math inline">\(L\)</span> is <span
class="math inline">\(1\)</span>, not simply just the probability that
it is between negative infinity and infinity.</p></li>
</ol>
<p><br />
We know that the wavefunction is continuous. This means actually that it
must vanish at the walls <span class="math inline">\(x=0\)</span> and
<span class="math inline">\(x=L\)</span>, or otherwise it couldn’t drop
to <span class="math inline">\(0\)</span> straight afterwards. So <span
class="math inline">\(x=0\)</span> and <span
class="math inline">\(x=L\)</span> are walls. In other words, <span
class="math display">\[\Psi(0) = 0 = \Psi(L)\]</span><br />
Finally, within the region <span
class="math inline">\(x\in(0,L)\)</span>, we have <span
class="math inline">\(V(x)=0\)</span>. Thus the problem reduces to the
free particle inside the square well.<br />
<br />
We split the problem into three components: the first, investigating the
wavefunction inside the well, the second, investigating the wavefunction
outside the well, and finally, investigating the wavefunction on the
boundary lines <span class="math inline">\(x=0\)</span> and <span
class="math inline">\(x=L\)</span>; we will cover these in that
order.<br />
<br />
The first part of the problem, the problem of the wavefunction inside
the square well, is simply the free particle problem since the potential
is <span class="math inline">\(0\)</span>, within finite position
bounds. So, we once again have <span
class="math display">\[\frac{d^2\Psi}{dx^2} =
-{\frac{2mE}{\hbar^2}}\Psi\]</span> which has the solution <span
class="math display">\[\Psi(x)=Ae^{ikx}+Be^{-ikx}\]</span> for some
constants <span class="math inline">\(A,B\)</span>, where <span
class="math display">\[k=p/\hbar=\frac{\sqrt{2mE}}{\hbar}.\]</span> We
cannot yet determine these constants <span
class="math inline">\(A,B\)</span> until we look at the other boundary
conditions.<br />
<br />
The second component of the problem is the problem of the wavefunction
outside the well. We recall that the wavefunction <span
class="math display">\[\Psi(x)\]</span> is a probability distribution
function which returns a value given a position <span
class="math inline">\(x\)</span> which is its component in the basis and
therefore a probability amplitude for achieving that measurement of
<span class="math inline">\(x\)</span>. Given that outside the well we
have infinite potential, we must have probability zero of finding the
particle there. This means that the solution of the wavefunction must
also be <span class="math display">\[\Psi(x)=0 \mtab \forall
x\in(-\infty,0)\cup(L,\infty)\]</span><br />
The most important part of the problem comes, however, with the third
component of the problem- that of the wavefunction on the hard walls
<span class="math inline">\(x=0\)</span> and <span
class="math inline">\(x=L\)</span>. We have <span
class="math display">\[\Psi(x) = Ae^{ikx}+Be^{-ikx}\]</span> for some
constants <span class="math inline">\(A\)</span> and <span
class="math inline">\(B\)</span>. We can rewrite this with Euler’s
formula: <span class="math display">\[\begin{aligned}
e^{ix}&amp;=\cos(x)+i\sin(x)\\
\implies
Ae^{ikx}+Be^{-ikx}&amp;=A\cos(kx)+iA\sin(x)+B\cos(-kx)+iB\sin(-kx).
\end{aligned}\]</span> The cosine function is even and the sine function
is odd. Therefore we have <span
class="math display">\[Ae^{ikx}+Be^{-ikx}=(A+B)\cos(kx)+i(A-B)\sin(kx).\]</span>
Now, examining the wall conditions, we firstly have: <span
class="math display">\[\Psi(x=0) = 0\]</span><br />
But since <span class="math inline">\(\sin(0)=0\)</span> this means
<span class="math display">\[(A+B)\cos(kx)=(A+B)\cos(0)=0.\]</span>
However, <span class="math inline">\(\cos(0) \neq 0\)</span>. Therefore
we must conclude that <span class="math inline">\(A+B=0\)</span>.
However, if we conclude this fact then it must be true for all regions,
not simply just the wall <span class="math inline">\(x=0\)</span>, as
the wavefunction cannot simply morph as soon as it reaches <span
class="math inline">\(x=0\)</span>. Thus for the wavefunction of the
whole problem of the infinite square well, which we will now be covering
in trigonometric form, we can omit the first coefficient entirely and
therefore vanish the cosine term. We are left with <span
class="math display">\[\Psi(x) = i(A-B)\sin{kx}.\]</span><br />
Note that we have <span class="math display">\[A+B=0\]</span> so neither
of the individual constants <span class="math inline">\(A\)</span> and
<span class="math inline">\(B\)</span> can be <span
class="math inline">\(0\)</span>, or that would imply the other is <span
class="math inline">\(0\)</span>, and we would have (in exponential
form) <span class="math display">\[\Psi(x)=0e^{ikx}+0e^{-ikx}=0\]</span>
which is absurd. Now we can use the other boundary condition. <span
class="math display">\[\psi(x=L)=0 \Rightarrow\:\:
i(A-B)\sin{kL}=0.\]</span><br />
If we had <span class="math display">\[A-B=0\]</span> then we would have
<span class="math display">\[A-B=A+B=0 \implies B=0 \implies
A=0\]</span> which is impossible as shown above. Therefore we must have
<span class="math display">\[\sin(kL)=0.\]</span> This means that we
must have <span class="math inline">\(kL=n\pi, \:\: n \in
\mathbb{Z}\)</span>. This means the wave number <span
class="math inline">\(k\)</span> is again quantized! Thus we can define.
<span class="math display">\[k_n=\frac{n\pi}{L}\]</span> which therefore
means we have discrete momenta: <span class="math display">\[p_{n}=\hbar
k_{n}=\frac{n\pi\hbar}{L}\]</span> and discrete energy: <span
class="math display">\[E_{n}=\frac{p_{n}^2}{2m}=\frac{\hbar^2\pi^2
n^2}{2mL^2}\stab.\]</span> Plugging in to our original general solution
for the wavefunction, we have the complete set of solutions <span
class="math display">\[\Psi_{n}(x)=N\sin\left(\frac{n\pi
x}{L}\right).\]</span> The constant <span
class="math inline">\(N\)</span> is a normalisation constant, which
incorporates <span class="math inline">\(i(A-B)\)</span>, which we had
before. It must be remembered that <span
class="math inline">\(A\)</span> and <span
class="math inline">\(B\)</span> are arbitrary constants which really
are not very important, so rolling them into a new constant <span
class="math inline">\(N\)</span> is not a big problem. We can restrict
ourselves to considering <span class="math inline">\(n \in
\mathbb{Z}^+\)</span> since the parity of the wavefunction is irrelevant
in producing the same results. This time, we will solve for the
normalisation constant <span class="math inline">\(N\)</span>. <span
class="math display">\[\int_{0}^{L}\Psi^\ast(x)\Psi(x)\,dx =
N^2\int_{0}^{L}\sin^2\left(\frac{n\pi x}{L}\right) \,dx\]</span> since
the sine function is real valued so its complex conjugate is itself.
Then, <span class="math display">\[N^2\int_{0}^{L}\sin^2\left(\frac{n\pi
x}{L}\right) \,dx = 1\]</span><br />
The integral requires some algebra to evaluate. Using the trigonometric
identity <span
class="math inline">\(\sin^2{kx}=\frac{1-\cos{2kx}}{2}\)</span>, we get:
<span class="math display">\[\begin{aligned}
&amp;\sin^2{kx}=\frac{1-\cos{2kx}}{2}\\
\Rightarrow\:\:
&amp;\int_{0}^{L}\sin^2{kx}=\int_{0}^{L}\frac{1-\cos{2kx}}{2}\\
\Rightarrow\:\:
&amp;\int_{0}^{L}\sin^2{kx}=\int_{0}^{L}\frac{1}{2}-\int_{0}^{L}\frac{1}{2}{\cos{2kx}}\\
\Rightarrow\:\:
&amp;\int_{0}^{L}\sin^2{kx}=\int_{0}^{L}\frac{d}{dx}\left(\frac{1}{2}x+c\right)-\frac{1}{2}\int_{0}^{L}\frac{d}{dx}\left({\frac{1}{2k}\sin{2kx}}\right)\\
\Rightarrow\:\:
&amp;\int_{0}^{L}\sin^2{kx}=\biggl[\frac{1}{2}x+c\biggr]_{0}^{L}-\biggl[\frac{1}{2k}\sin{2kx}\biggr]_{0}^{L}\\
\Rightarrow\:\:
&amp;\int_{0}^{L}\sin^2{kx}=\frac{L}{2}-\biggl[\frac{1}{2k}\sin{2kx}\biggr]_{0}^{L}\\
\end{aligned}\]</span><br />
Now, plugging in <span class="math inline">\(k=\frac{n\pi}{L}\)</span>,
we get: <span class="math display">\[\begin{aligned}
\int_{0}^{L}\sin^2\left(\frac{n\pi x}{L}\right) \,dx &amp;=
\frac{L}{2}-\biggl[\frac{L}{n\pi}\sin\left(\frac{2n\pi
a}{L}\right)-\frac{1}{2k}\sin{0}\biggr]\\
&amp;=\frac{L}{2}-\biggl[\frac{L}{n\pi}\sin{2n\pi}-0\biggr]\\
&amp;=\frac{L}{2}
\end{aligned}\]</span><br />
since <span class="math inline">\(\sin{2n\pi}=0\)</span>. So for the
normalisation constant we have evaluated the integral from <span
class="math inline">\(0\)</span> to <span
class="math inline">\(L\)</span> and get: <span
class="math display">\[N^2\int_{0}^{L}\sin^2\left(\frac{n\pi
x}{L}\right) \,dx=\frac{N^2L}{2}=1 \Rightarrow\:\:
N=\sqrt{\frac{2}{L}}\]</span> as our normalisation constant. That gives
us the following set of normalised solutions indexed by positive
integers <span class="math inline">\(n\)</span>: <span
class="math display">\[\Psi_n=\sqrt{\frac{2}{L}}\sin\left(\frac{n\pi
x}{L}\right).\]</span> We can confirm these are orthogonal to each other
for different <span class="math inline">\(n\)</span> and thus create an
orthonormal set. The normalised property is covered by the normalisation
coefficient <span class="math inline">\(\sqrt{{2}/{L}}\)</span>, and the
orthogonality can be proved by considering the inner product- from <span
class="math inline">\(x=0\)</span> to <span
class="math inline">\(x=L\)</span> since this is the domain of the
wavefunction without it vanishing. <span
class="math display">\[\begin{aligned}
    \int_{0}^{L} \psi^\ast_m(x)\psi_n(x) \,dx =
\left(\sqrt{\frac{2}{L}}\right)^2\int_{0}^{L}\sin\left(\frac{m\pi
x}{L}\right)\sin\left(\frac{n\pi x}{L}\right)\,dx
    \end{aligned}\]</span><br />
since the complex conjugate of the real valued sine function is itself.
Then: <span class="math display">\[\begin{aligned}
    \sin{x}\sin{y}&amp;= \frac{1}{2}[\cos(x-y)+\cos(x+y)]\\
    &amp;\Rightarrow\:\: \frac{2}{L}\int_{0}^{L}\sin\left(\frac{m\pi
x}{L}\right)\sin\left(\frac{n\pi x}{L}\right)\,dx\\
    &amp;=\frac{2}{L}\int_{0}^{L}\frac{1}{2}\biggl[\cos\left(\frac{(m-n)\pi
x}{L}\right)+\cos\left(\frac{(m+n)\pi x}{L}\right)\biggr]\\
    &amp;= \frac{1}{L}\int_{0}^{L}\biggl[\cos\left(\frac{(m-n)\pi
x}{L}\right)+\cos\left(\frac{(m+n)\pi x}{L}\right)\biggr]\\
    \end{aligned}\]</span><br />
Using some chain rule: <span
class="math display">\[\frac{d}{dx}\sin\left(\frac{(m-n)\pi
x}{L}\right)=
\frac{d}{dg}\sin(g(x))*\frac{d}{dx}\frac{(m-n)\pi}{L}x\]</span><br />
where <span class="math inline">\(g(x) = \frac{(m-n)\pi}{L}x\)</span>.
Then this means: <span
class="math display">\[\frac{d}{dx}\sin\left(\frac{(m-n)\pi
x}{L}\right)=\frac{(m-n)\pi}{L}\cos\left(\frac{(m-n)\pi}{L}x\right)\]</span>
And therefore, <span
class="math display">\[\cos\left(\frac{(m-n)\pi}{L}x\right)=
\frac{L}{(m-n)\pi}\frac{d}{dx}\sin\left(\frac{(m-n)\pi
x}{L}\right)\]</span><br />
so we doing something similar with the <span
class="math inline">\(\cos(\frac{(m+n)\pi x}{L})\)</span> term we can
write the integral as: <span
class="math display">\[\frac{1}{L}\int_{0}^{L}\biggl[\left(\frac{L}{(m-n)\pi}\right)\frac{d}{dx}\sin\left(\frac{(m-n)\pi}{L}x\right)+\left(\frac{L}{(m+n)\pi}\right)\frac{d}{dx}\sin\left(\frac{(m+n)\pi}{L}x\right)\biggr]\]</span><br />
then, pulling out constants and using the fundamental theorem of
calculus to get rid of the integral, we get the expression <span
class="math display">\[\biggl[\frac{1}{(m-n)\pi}\sin\left(\frac{(m-n)\pi}{L}x\right)+\frac{1}{(m+n)\pi}\sin\left(\frac{(m+n)\pi}{L}x\right)\biggr]_{0}^{L}\]</span><br />
clearly at <span class="math inline">\(x=0\)</span> we get a bunch of
<span class="math inline">\(\sin(0)\)</span> terms so the large bracket
is 0. At <span class="math inline">\(x=L\)</span> the value of <span
class="math inline">\(x\)</span> cancels with the denominator inside the
sine function, and so we get the sine values of <span
class="math inline">\(m-n\in\mathbb{Z}^{+}\)</span> lots of <span
class="math inline">\(\pi\)</span>, which also ends up with 0. So
altogether we have proved the whole integral and therefore the inner
product of <span class="math inline">\(\Psi_m\)</span> and <span
class="math inline">\(\Psi_n\)</span> is <span
class="math inline">\(0\)</span>. Note that the whole process is invalid
when <span class="math inline">\(m=n\)</span> since then the fraction
<span class="math inline">\(\frac{L}{(m-n)\pi}\)</span> we see in the
expression of <span
class="math inline">\(\cos(\frac{(m-n)\pi}{L}x)\)</span> as a derivative
is clearly invalid due to division by <span
class="math inline">\(0\)</span>. Now we can summarise: <span
class="math display">\[\ip{\Psi_{m}}{\Psi_{n}} = \delta_{n,m}\]</span>
which is our original definition of an orthogonal set of wavefunctions
<span class="math inline">\(\ket{\Psi}\)</span>. So indeed, the set of
<span class="math inline">\(\Psi_{n}\)</span> indexed by integers <span
class="math inline">\(n\)</span> is an orthonormal set of states which
can then be linearly combined into any superposition of states with
different probabilities.</p>
<h4 id="analysing-solutions">Analysing solutions</h4>
<p>We can summarise our numerical analysis of eigenstates as follows. We
obtained: <span
class="math display">\[\psi_n=\sqrt{\frac{2}{L}}\sin(\frac{n\pi x}{a}),
\:\:\:\:\: E_n=\frac{\hbar^2\pi^2 n^2}{2ma^2}, \:\:\:\:\: n \in
\mathbb{Z}^+\]</span><br />
<br />
We can now plot the first <span class="math inline">\(\psi_n\)</span> on
an axis from <span class="math inline">\(0\)</span> to <span
class="math inline">\(a\)</span>. This is in shown in figure 1. Clearly,
we observe a few properties:</p>
<ol>
<li><p>We call a zero of <span class="math inline">\(\psi\)</span>
inside the domain of <span class="math inline">\(\psi\)</span> a node.
Then here we see that <span class="math inline">\(\psi_n\)</span> has
<span class="math inline">\(n-1\)</span> nodes: the zeros at <span
class="math inline">\(x=0\)</span> and <span
class="math inline">\(x=a\)</span> do not count as they are not inside
the domain. More importantly, for this set of solutions to <span
class="math inline">\(\psi\)</span> for every <span
class="math inline">\(1\)</span> that you increase the integer indexing
<span class="math inline">\(\psi_n\)</span> you also increase the number
of nodes by <span class="math inline">\(1\)</span>. This is actually
generally true as you go up from the ground state- the lowest energy
state and nearly always <span class="math inline">\(\psi_1\)</span> in a
set of <span class="math inline">\(\psi_n, \:\: n \in
\mathbb{Z}^+\)</span>: for any set of solutions <span
class="math inline">\(\psi\)</span> we add 1 node every time we move to
the next possible energy level.<br />
</p></li>
<li><p>The <span class="math inline">\(\psi_n\)</span> are clearly
alternately symmetric and asymmetric as you go up index numbers <span
class="math inline">\(n\)</span>. <span
class="math inline">\(\psi_1\)</span> is symmetric, <span
class="math inline">\(\psi_2\)</span> is asymmetric, <span
class="math inline">\(\psi_3\)</span> is symmetric, etc. Crucially, we
call symmetric solutions <strong>even</strong> and the asymmetric
solutions <strong>odd</strong>. The definition of an even function <span
class="math inline">\(f(x)\)</span> is that <span
class="math inline">\(f(x)=f(-x)\)</span>. The definition of an odd
function is where <span class="math inline">\(f(-x)=-f(x)\)</span>.
Technically here there are neither even solutions nor odd solutions
since this is not true for any <span
class="math inline">\(\psi_n\)</span> in the question defined. But if we
had taken the midpoint of the well to be <span
class="math inline">\(x=0\)</span> then looking at the first few
wavefunctions it is clear this would have been true, so the parity of
functions we think in is analogous. We will see in our next problem how
important discussion of function parity will be in breaking down
questions as they get more and more complex and we seek to categorise
more and more realistic situations and problems. But there exists a
powerful fact: if a particle is in an even potential then all
wavefunctions are either odd or even. In this problem again if we had
set the middle of the potential well to be <span
class="math inline">\(0\)</span> then we would have seen an example of
this fact: the potential would be even since it is symmetric about <span
class="math inline">\(0\)</span> and the solutions are alternately even
and odd. Clearly this is an exceptionally meaningful fact. We can prove
it fairly easily for our one-dimensional purposes: <span
class="math display">\[\text{By Schrodinger}, \:\:
-{\frac{\hbar^2}{2m}\frac{d^2}{dx^2}}\psi(x)+V(x)\psi(x)=E\psi(x)\]</span><br />
when we substitute in <span class="math inline">\(x=-x\)</span>, we get:
<span
class="math display">\[-{\frac{\hbar^2}{2m}\frac{d^2}{dx^2}}\psi(-x)+V(-x)\psi(-x)=E\psi(-x)\]</span><br />
we are considering a question where the potential is even and thus <span
class="math inline">\(V(x)=V(-x)\)</span> So then: <span
class="math display">\[-{\frac{\hbar^2}{2m}\frac{d^2}{dx^2}}\psi(-x)+V(x)\psi(-x)=E\psi(-x)\]</span><br />
we step back out of the algebraic manipulation and see that clearly this
means that if <span class="math inline">\(\psi(x)\)</span> is a solution
in an even potential then <span class="math inline">\(\psi(-x)\)</span>
is also a solution. This in itself is very important, naturally. But
since we are working in the same one-dimensional vector space of
solutions to the same Schrodinger then it is impossible for these two
functions to be linearly independent, or orthogonal in a one-dimensional
space. Therefore we can say <span
class="math display">\[\psi(x)=a\psi(-x)\]</span><br />
for some constant <span class="math inline">\(a\)</span>. Then <span
class="math inline">\(a\psi(-x)=\psi(x)\)</span>, so it satisfies the
conditions, and therefore is normalised. So we have: <span
class="math display">\[|a|^2\int_{-\infty}^{\infty}\psi^{\ast}(-x)\psi(-x)\,dx=1\]</span><br />
But <span class="math inline">\(\psi(-x)\)</span> itself is a normalised
solution so the integral is equal to 1. Therefore <span
class="math display">\[|a|^2=1 \Rightarrow\:\:\:\: a=\pm1\]</span> By
definition when <span class="math inline">\(a=1\)</span> then <span
class="math inline">\(\psi\)</span> is even since we get <span
class="math inline">\(\psi(x)=\psi(-x)\)</span>, and when <span
class="math inline">\(a=-1\)</span> then <span
class="math inline">\(\psi\)</span> is odd, since we get <span
class="math inline">\(\psi(x)=-\psi(x)\)</span>. Therefore for an even
potential all solutions <span class="math inline">\(\psi\)</span>, when
normalised, must be even or odd.</p></li>
</ol>
<h2 id="harmonic-oscillator">Harmonic Oscillator </h2>
<p>We now introduce a third less fundamental but perhaps more impactful
problem which must be included in any discussion of quantum mechanics.
We will take one system we know very well from classical mechanics, the
spring, which has a potential of <span
class="math display">\[V(x)=\frac{1}{2}kx^2\]</span> for the spring
constant <span class="math inline">\(k\)</span>. This can also be
written via the angular frequency, <span
class="math inline">\(\omega=k/m\)</span>, as <span
class="math display">\[V(x)=\frac{1}{2}mX\omega^{2}.\]</span> There is
the standard method of solving this problem in the quantum mechanical
version, where the Hamiltonian is <span
class="math display">\[\hat{H}=\frac{\hat{P}^2}{2m}+\frac{1}{2}m\hat{X}^{2}\omega^{2}.\]</span>
We note that for the system the spring constant and mass are both
constants, and so <span class="math inline">\(\omega=k/m\)</span> is a
constant and therefore should not and cannot be replaced by an
expression in the position and momentum operators for the quantum
Hamiltonian. Now the conventional method would be to solve the problem
in position space and implement strategies much like we have shown
above. But there is a method, courtesy of Dirac, which shows that we can
use the energy eigenbasis as well.<br />
<br />
In principle this should be difficult, as to find the energy eigenkets
which form the energy eigenbasis is tantamount to solving for the
propagator for time evolution, in which case it is unclear why we would
ever need to be in the energy eigenbasis after that. However, elegance
will show in a clever way this limitation is not quite concrete for all
problems, and the energy eigenbasis can be very useful even before we
know the eigenvectors.<br />
<br />
To start, we define the operator <span
class="math display">\[a=\sqrt{\frac{m\omega}{2\hbar}}\left(\hat{X}+\frac{i\hat{P}}{m\omega}\right).\]</span>
Then we consider its hermitian adjoint, <span
class="math display">\[a^{\dagger}=\sqrt{\frac{m\omega}{2\hbar}}\left(\hat{X}-\frac{i\hat{P}}{m\omega}\right).\]</span>
It is clear these operators are not hermitian. What relationship is held
by the two operators? They turn out not to be unitary either. Instead,
we get <span class="math display">\[[a,a^{\dagger}]=1\]</span> which can
be easily verified: <span class="math display">\[\begin{aligned}
[a,a^{\dagger}]&amp;=\frac{m\omega}{2\hbar}\left[\biggl(\hat{X}+\frac{i\hat{P}}{m\omega}\biggr)\biggl(\hat{X}-\frac{i\hat{P}}{m\omega}\biggr)\right]-\frac{m\omega}{2\hbar}\biggl[\left(\hat{X}-\frac{i\hat{P}}{m\omega}\right)\left(\hat{X}+\frac{i\hat{P}}{m\omega}\right)\biggr]\\
&amp;=\frac{m\omega}{2\hbar}\biggl[\hat{X}^{2}-\frac{i}{m\omega}[\hat{X},\hat{P}]-\left(\frac{i\hat{P}}{m\omega}\right)^2-\hat{X}^2-\frac{i}{m\omega}[\hat{X},\hat{P}]+\left(\frac{i\hat{P}}{m\omega}\right)^2\biggr]\\
&amp;=\frac{m\omega}{2\hbar}\biggl[-\frac{i}{m\omega}(2i\hbar)\biggr]=\frac{m\omega}{2\hbar}\frac{2\hbar}{m\omega}=1
\end{aligned}\]</span> Finally, we can define an operator, <span
class="math inline">\(N\)</span>, to be <span
class="math inline">\(a^{\dagger}a:=N\)</span>. This operator is
hermitian as <span class="math inline">\(a^{\dagger}a\)</span>. This
operator has the form, as seen above: <span
class="math display">\[\begin{aligned}
N&amp;=\frac{m\omega}{2\hbar}\biggl[\hat{X}^2+\frac{i}{m\omega}[\hat{X},\hat{P}]-\left(\frac{i\hat{P}}{m\omega}\right)^2\biggr]=\left(\frac{m\omega}{2\hbar}\right)\left[\hat{X^2}+\frac{\hat{P}^2}{m^2\omega^2}+\frac{i}{m\omega}[\hat{X},\hat{P}]\right]\\
&amp;=\frac{1}{\hbar\omega}\frac{\hat{P}^2}{2m}\frac{1}{2\hbar}+{\hat{X}^2}m\omega+\frac{i}{2\hbar}i\hbar
\end{aligned}\]</span> Regarding the Hamiltonian of the system again,
this is <span
class="math display">\[N=\frac{\hat{H}}{\hbar\omega}-\frac{1}{2}\implies\hat{H}=\hbar\omega\left(N+\frac{1}{2}\right).\]</span>
A bit of clever compatibility thinking is again the step here.
Technically <span class="math inline">\(N\)</span> is not an observable
operator, but note that what we proved about compatible observables did
not hinge on the fact that the operators were Hermitian or had real
eigenvalues. Only the third component, that about successive
measurements of different observables and whether or not they affect the
eigenstate, was contingent on the discussion being about observables in
the other place. In other words, if two operators commute they possess a
common eigenbasis; this is not simply limited to observable operators,
as a review of the proof we gave will show.<br />
<br />
We have seen above that the operator <span
class="math inline">\(N\)</span> is a linear combination of the
Hamiltonian. This means that they will commute. This in turn means that
they possess a common eigenbasis! Thus there exist energy eigenkets
<span class="math inline">\(\ket{E}\)</span> which are also eigenkets of
the operator <span class="math inline">\(N\)</span>. Thus we have the
relationship <span
class="math display">\[\hat{H}\ket{E}=E\ket{E}\]</span> as usual, but
also the relationship <span
class="math display">\[N\ket{E}=n\ket{E}\]</span> for some eigenvalue
<span class="math inline">\(n\)</span>. We can now equate the
eigenvalues! <span
class="math display">\[\hat{H}\ket{E}=\hbar\omega\left(N+\frac{1}{2}\right)\ket{E}=\hbar
\omega
N\ket{E}-\frac{\hbar\omega}{2}\ket{E}=\hbar\omega\left(n+\frac{1}{2}\right)\ket{E}\]</span>
So the energy eigenvalues are given by <span
class="math display">\[E_{n}=\left(n+\frac{1}{2}\right)\hbar\omega.\]</span>
The author has tried to instil a justified suspicion in the reader for
indexing by <span class="math inline">\(n\)</span> without knowing there
is a discrete case which can be indexed by integers; indeed, we still do
not know anything about the eigenvalues <span
class="math inline">\(n\)</span> so energy could still well be
continuous at this stage, and indexing by <span
class="math inline">\(n\)</span> would be meaningless. However, we will
soon prove that in this case this step is fine as the eigenvalues of
<span class="math inline">\(N\)</span> are in fact nonnegative integers
<span class="math inline">\(n\)</span>! We will from now on refer to
<span class="math inline">\(N\)</span> as the counting operator, as is
widespread convention. Let us consider some more commutation
relations.<br />
<br />
By the commutation relation <span
class="math display">\[[AB,C]=A[B,C]+[A,C]B\]</span> we have <span
class="math display">\[[N,a^{\dagger}]=[a^{\dagger}a,a^{\dagger}]=a^{\dagger}[a,a^{\dagger}]+[a^{\dagger},a^{\dagger}]a=a^{\dagger}(1)+0=a^{\dagger}.\]</span>
Now we also have <span
class="math display">\[[N,a^{\dagger}]=Na^{\dagger}-a^{\dagger}N\implies
Na^{\dagger}=a^{\dagger}N+[N,a^{\dagger}]=a^{\dagger}N+a^{\dagger}.\]</span>
Thus applying the operator to an energy eigenket, now indexed by <span
class="math inline">\(n\)</span>, <span
class="math display">\[Na^{\dagger}\ket{E_{n}}=(a^{\dagger}N+a^{\dagger})\ket{E_{n}}=a^{\dagger}N\ket{E_{n}}+a^{\dagger}\ket{E_{n}}=(n+1)a^{\dagger}\ket{E_{n}}.\]</span>
The reader will recognise the above as another eigenvalue equation,
which states that for the counting operator, we have <span
class="math display">\[N\ket{E_{n}}=n\ket{E_{n}}\]</span> as one
eigenvalue equation, but also the ket <span
class="math inline">\(a^{\dagger}\ket{E_{n}}\)</span> as an eigenket
which has an eigenvalue <span class="math inline">\(n+1\)</span> such
that as above, the equation <span
class="math display">\[N(a^{\dagger}\ket{E_{n}})=(n+1)(a^{\dagger}\ket{E_{n}})\]</span>
applies. We have mentioned that <span class="math inline">\(n\)</span>
is a nonnegative integer, so what this is really saying is that if we
apply the counting operator <span
class="math inline">\(\ket{E_{n}}\)</span>, we get the of an eigenvalue
<span class="math inline">\(n\)</span>, but if we then change the
eigenket by applying the operator <span
class="math inline">\(a^{\dagger}\)</span> to it first, and then apply
the counting operator, we will now count the eigenvalue <span
class="math inline">\(n+1\)</span>. What is the physical meaning of
<span class="math inline">\(n\)</span>? Well, we have <span
class="math display">\[E_{n}=\left(n+\frac{1}{2}\right)\hbar\omega.\]</span>
The meaning of <span class="math inline">\(\hbar\omega\)</span> is
interesting: one unit we can choose for the Planck’s constant <span
class="math inline">\(\hbar\)</span> is joules per hertz, and the
angular frequency, as suggested by the name, can be measured in hertz,
which means that units of <span
class="math inline">\(\hbar\omega\)</span> are measured in joules-
thereby a measure of energy. Of course, the value of <span
class="math inline">\(\hbar\omega\)</span> is not <span
class="math inline">\(1\)</span> Joule, since the angular frequency
would have to be unthinkable for this to be true, but we can think of
<span class="math inline">\(\hbar\omega\)</span> as small of energy (in
a loose intuitive manner) which we can use to measure the energy of the
system it turns out very appropriately on the microscopic scale. The
basic analogy one has already seen in their own studies? Coulombs as a
measure of charge, which are also technically of electrons (again in a
very loose manner) which help make the counting process easier!<br />
<br />
Thus every time we increase <span class="math inline">\(n\)</span> we
increase the energy reading. When <span class="math inline">\(n\)</span>
is measured that corresponds to when the counting operator acts on the
energy eigenket <span class="math inline">\(\ket{E_{n}}\)</span>, and
the corresponding energy is <span class="math inline">\(n+1/2\)</span>
in units <span class="math inline">\(\hbar\omega\)</span>. However, if
we apply <span class="math inline">\(a^{\dagger}\)</span> to <span
class="math inline">\(\ket{E_{n}}\)</span> first, we replace <span
class="math inline">\(n\)</span> with <span
class="math inline">\(n+1\)</span>, thereby replacing the corresponding
energy <span class="math inline">\(n+1/2\)</span> with the energy <span
class="math inline">\(n+1+1/2\)</span>. Thus the operator <span
class="math inline">\(a^{\dagger}\)</span> <strong>creates</strong> one
unit of energy, measured in <span
class="math inline">\(\hbar\omega\)</span>- giving it is name.
Similarly: <span
class="math display">\[[N,a]=[a^{\dagger}a,a]=a^{\dagger}[a,a]+[a^{\dagger},a]a=a^{\dagger}(-1)+0=-a.\]</span>
Now we also have <span class="math display">\[[N,a]=Na-aN\implies
Na=aN+[N,a]=aN-a.\]</span> Thus applying the operator to an energy
eigenket, now indexed by <span class="math inline">\(n\)</span>, <span
class="math display">\[Na\ket{E_{n}}=(aN-a)\ket{E_{n}}=aN\ket{E_{n}}-a\ket{E_{n}}=(n-1)a\ket{E_{n}}.\]</span>
Which, by the same argument as above, shows that the operator <span
class="math inline">\(a\)</span> acting on a energy eigenstate <span
class="math inline">\(E_{n}\)</span> <strong>annihilates</strong>
(dramatic, but conventional) one unit of energy <span
class="math inline">\(\hbar\omega\)</span>! Thus the names the creation
operator for <span class="math inline">\(a^{\dagger}\)</span> and the
annihilation operator for <span class="math inline">\(a\)</span>.<br />
<br />
Next, we wonder if there is an easier way to label the kets <span
class="math inline">\(a^{\dagger}\ket{E_{n}}\)</span> and <span
class="math inline">\(a\ket{E_{n}}\)</span>, which we have also noted
are eigenkets of the counting operator. Well, of course there is- <span
class="math display">\[N\ket{E_{n+1}}=(n+1)\ket{E_{n+1}}, \btab
Na^{\dagger}\ket{E_{n}}=(n+1)a^{\dagger}\ket{E_{n}}\implies
a^{\dagger}\ket{E_{n}}\equiv \ket{E_{n+1}}.\]</span> This is completely
reasonable, because <span class="math inline">\(a^{\dagger}\)</span> on
the state <span class="math inline">\(\ket{E_{n}}\)</span> raises the
energy by <span class="math inline">\(1\)</span>. However, by the
formula <span
class="math display">\[E_{n}=\left(n+\frac{1}{2}\right)\hbar\omega,\]</span>
and the fact we have taken it as a given that <span
class="math inline">\(n\in\mathbb{Z}^{+}\)</span>, we must have <span
class="math inline">\(E_{n+1}=E_{n}+1\times\hbar\omega\)</span>, in
which case the equivalence of the states <span
class="math inline">\(a^{\dagger}\ket{E_{n}}\)</span> and <span
class="math inline">\(\ket{E_{n+1}}\)</span> makes perfect sense.
Similarly, of course, <span class="math inline">\(a\ket{E_{n}}\)</span>
and <span class="math inline">\(\ket{E_{n-1}}\)</span> are equivalent
states. Yet we know that equivalence is not algebraic equality: rather,
<span class="math display">\[a\ket{E_{n}}=c\ket{E_{n-1}}\]</span> for
some multiplicative constant <span class="math inline">\(c\)</span> is
sufficient for them to be equivalent states. The norm of <span
class="math inline">\(a\ket{E_{n}}\)</span> is <span
class="math display">\[\nhoptrip{E_{n}}{a^{\dagger}\:a}{E_{n}}=\nhoptrip{E_{n}}{N}{E_{n}}\]</span>
by our correspondence <span
class="math display">\[\Omega\ket{X}\duac\bra{X}\Omega^{\dagger}.\]</span>
This is then equal to <span
class="math display">\[|c|^2\sip{E_{n-1}}=|c|^2\]</span> given the
definition of <span class="math inline">\(c\)</span> above and the
assumption that <span class="math inline">\(\ket{E_{n+1}}\)</span> has
already been normalised. So we have <span
class="math display">\[\nhoptrip{E_{n}}{N}{E_{n}}=n\sip{E_{n}}=n=|c|^2\implies
c=\sqrt{n}.\]</span> Thus we have <span
class="math display">\[a\ket{E_{n}}=\sqrt{n}\ket{E_{n-1}}.\]</span> We
can do the exact same thing for <span
class="math inline">\(a^{\dagger}\)</span> to get <span
class="math display">\[a^{\dagger}\ket{E_{n}}=\sqrt{n+1}\ket{E_{n+1}}.\]</span>
By the semidefinite metric, the norm of any ket, including <span
class="math inline">\(a\ket{E_{n}}\)</span> is positive. However, the
norm of <span class="math inline">\(a\ket{E_{n}}\)</span> is <span
class="math inline">\(n\)</span> as already shown. Thus, <span
class="math inline">\(n\)</span> must be nonnegative. We next realise
that all we have covered so far means that <span
class="math display">\[(a^{2})\ket{E_{n}}=a\sqrt{n}\ket{E_{n-1}}=\sqrt{n}a\ket{E_{n-1}}=\sqrt{n(n-1)}\:\ket{E_{n-2}}\]</span>
and so on- in other words, applying the annihilation operator means we
should be able keep annihilating energy in units of <span
class="math inline">\(\hbar\omega\)</span> until we reach a negative
value of <span class="math inline">\(n\)</span>, no matter how great the
<span class="math inline">\(n\)</span> and therefore energy. The reason
this is problematic, however, is that we have already proven that the
counting operator eigenvalue <span class="math inline">\(n\)</span>
corresponding to the energy and counting simultaneous eigenstate <span
class="math inline">\(\ket{E_{n}}\)</span> must be nonnegative due to
the semidefinite postulate. So we cannot expect a negative value of
<span class="math inline">\(n\)</span> to appear. As we have <span
class="math display">\[a\ket{E_{n}}=\sqrt{n}\ket{E_{n-1}}\]</span> We
conclude that if we reach a <span class="math inline">\(E_{n}\)</span>
with <span class="math inline">\(n&lt;0\)</span> the definition means we
must have reached an eigenvalue <span
class="math inline">\(n&lt;0\)</span>. The fact above with the sequence
of square roots shown by repeatedly applying the annihilation operator
shows that clearly we should be able to reach a state <span
class="math inline">\(E_{n}\)</span> with <span
class="math inline">\(n&lt;0\)</span>. This is unless we terminate at a
value before we reach below <span class="math inline">\(n=0\)</span>. If
after annihilating a sufficient number of <span
class="math inline">\(\hbar\omega\)</span> units of energy we had <span
class="math inline">\(n\in(0,1)\)</span> then we would be able to apply
the annihilation operator again to get a new <span
class="math inline">\(n&#39;=n-1\in(-1,0)\)</span> which is negative. If
we had a value of <span class="math inline">\(n&gt;1\)</span> which was
not an integer then we conclude we must be able to keep applying the
annihilation operator until we get a value in the region <span
class="math inline">\((0,1)\)</span>, after which the same argument
applies that we reach a negative <span class="math inline">\(n\)</span>.
Thus we must have the value <span class="math inline">\(n=1\)</span>
occurring, after which reapplying the annihilation operator should give
<span class="math inline">\(n=0\)</span>. What if we now try to reapply
the annihilation operator? Well then, we have <span
class="math display">\[a\ket{E_{n}}=\sqrt{n}\ket{E_{n-1}}\implies
a\ket{E_{0}}=0\ket{E_{-1}}=0.\]</span> In other words, all negative
index <span class="math inline">\(E_{n}\)</span>, and therefore negative
<span class="math inline">\(n\)</span> disappear! This satisfies our
condition of being able to apply the annihilation operator repeatedly
but not ever having states where the counting operator eigenvalue <span
class="math inline">\(n\)</span> is negative. Thus we have shown with
this argument, which should be reread if one is not convinced, that all
we have done thus far on the assumption that the eigenvalues <span
class="math inline">\(n\)</span> are integers was done on the correct
assumption: <span class="math inline">\(n\)</span> must be a nonnegative
integer, and there is a terminating state <span
class="math inline">\(\ket{E_{0}}\)</span> which has energy <span
class="math inline">\(E_{0}=(0+1/2)\hbar\omega=(1/2)\hbar\omega\)</span>.</p>
</body>
</html>
