\chapter{Chapter 5: Commutation Relations}
Another question still remains. We know that state vectors represent states-- and that is, physical states. If we think to use our classical intuition, we know a physical state can be thought about from the perspective of one observable (such as when we consider the momentum of two colliding objects). However, that does not mean it does not possess any values for all other physical observables, as it still has energy, angular momentum, and so on: only that we are not currently considering the other observables. Similarly, we would not be particularly pleased if the physical states pertaining to a certain measurement of one specific observable-- these so called pure states-- suddenly contained absolutely no information on any other observables. This is a question of information encapsulation: how does an energy pure state store extractable information about momentum, for example? To understand this question, which is far more complicated than the classical one of ``it's there, and just hasn't been measured yet'', we treat the two seminal theorems on the matter. Along the way, we will also be able to practise the mathematical operations we have introduced at a level and intensity we have not had the occasion to do so far.
\\\\
We have already seen in the last chapter how important the commutation relation between two observable operators in our Hilbert space can be. Starting from Dirac's Canonical Commutation relation, we deduced the form of the position and momentum operators in both the position and momentum space.
\\\\
Here, we explore more consequences of the commutation relation between two arbitrary observable operators.
\section{The Position and Momentum Operators}
Very early on in classical mechanics, it was already established that two observables, position and momentum, are enough to completely specify the state of a single body. We will not concern ourselves with why that is true, but the same logic carries over to quantum mechanics. There are three operators which are by far the most important:
\section{Simultaneous states}
The question of ``simultaneous states'' deals with the segue from the previous section onto this one. We want to investigate which states (state vectors) can contain information on multiple observables at a time, and which observables these are. We have seen in the Stern Gerlach experiment that for example $x$ and $y$ spin simultaneous states are impossible, so this is a relevant, fully quantum in nature, problem.
\\\\
It turns out that the ability for different observables to have information represented in the same state vectors depends strongly on the relationship between their observable operators, as these in turn relate their orthonormal eigenvectors. To see this, there is one sweeping but simple theorem on operators for observables which can be measured simultaneously, and one dramatically anticlassical one for observables which cannot.
\subsection{The Compatibility Theorem}
Consider an unperturbed system, two physical observables, and three measurements ordered chronologically. The first and third measurements are for the first physical observable, but the second measurement is for the second observable. We know from the Measurement Postulate that:
\begin{itemize}
    \item The first measurement forces the wavefunction into a pure eigenstate of the first physical observable operator. 
    \item The second measurement forces the wavefunction into a pure eigenstate of the second physical observable operator.
    \item If the second measurement of the different observable did not exist, then we would have successive measurements of the same state (which is, the operator acting on the same eigenstate the starting state vector was forced into following the first measurement) and we would expect the same measurement for the observable as we originally obtained.
\end{itemize}
The question is therefore whether or not this second measurement changes the result of the third. This is a profound question, because if it does, then we would conclude the simple act of measuring the second observable has moved the state vector out of the pure eigenstate it was in after the first measurement; that would then imply the second measurement is in itself a perturbation to the system: a confusing result. Indeed-- the reader will recognise that this is exactly the class of behaviour which appeared so shockingly in the Stern Gerlach experiment.
\\\\ 
We shall see that the determining factor is what the relationship between the two observable operators is. To start off, we will use the notations $\mathcal{A}$ and $\mathcal{B}$ as shorthand to distinguish between the two observables, so we do not have to name them. We define $\mathcal{A}$ and $\mathcal{B}$ to be \textbf{compatible observables} if the first and third measurements yield the same value regardless of the starting state and the value of the second observable measured in the second measurement. If we call the values measured $\mathcal{A}^{(1)}$, $\mathcal{B}^{(1)}$, $\mathcal{A}^{(2)}$, then observable $\mathcal{A}$ and $\mathcal{B}$ are compatible iff 
$$
\forall\:\Psi,\:\mathcal{B}^{(1)},\:\:\mathcal{A}^{(1)}=\mathcal{A}^{(2)}.
$$
\textbf{Compatibility Theorem}: Two observables $\mathcal{A}$ and $\mathcal{B}$ are defined compatible if they possess a common eigenbasis or their operators commute. These three conditions in fact all imply each other.
\underline{Proof:}
\\\\
First we prove that $\hat{A}$ commutes with $\hat{B}$ iff they possess a common eigenbasis. Consider two observable operators which commute, and define their eigenbases to be $\{\bm{\alpha}_{i}\}$ and $\{\bm{\beta}_{i}\}$. Now take an arbitrary eigenvector $\bm{\alpha}_{i}$ of $\hat{A}$ with eigenvalue $A_{i}$. We have
$$
\hat{A}\hat{B}=\hat{B}\hat{A}
$$
so we get 
$$
\hat{A}\hat{B}\bm{\alpha}_{i}=\hat{B}\hat{A}\bm{\alpha}_{i}=\hat{B}A_{i}\bm{\alpha}_{i}.
$$
However, we can now pull the constant eigenvalue out:
$$
\hat{A}(\hat{B}\bm{\alpha}_{i})=A_{i}(\hat{B}\bm{\alpha}_{i})
$$
so clearly $\hat{B}\bm{\alpha}_{i}$ is an eigenvector of $\hat{A}$ corresponding to eigenvalue $A_{i}$. Assuming that the eigenvalues are nondegenerate this implies that $\hat{B}(\bm{\alpha}_{i})$ coincides with $\bm{\alpha}_{i}$ as the eigenvalue $A_{i}$ has only one distinguishable eigenvector. The fact that 
$$
\hat{B}\bm{\alpha}_{i}\equiv\bm{\alpha}_{i}
$$
means we must have
$$
\hat{B}\bm{\alpha}_{i}=c\bm{\alpha}_{i}
$$
for some scalar multiple $c$. This means that $\bm{\alpha}_{i}$ is an eigenvector of $\hat{B}$ corresponding to eigenvalue $c$. So we can say that $\forall\:i, \bm{\alpha}_{i}$ is an eigenvector of $\hat{A}$ and $\hat{B}$: which means that they have the same eigenbasis. This isn't of course, to say, the eigenvalues are the same for $\hat{B}$ and $\hat{A}$ even though it may correspond to the same eigenvector (above, they are not the same unless $A_{i}=c$), since we expect the operators to be formulated differently so there will still be different values measured for each observable. Yet at the same time this is clearly helpful: if we know two physical observable operators commute and we have the eigenbasis of one then we automatically have the eigenbasis of the other. 
\\\\
Now, we prove it the other way around. Assume $\hat{A}$ and $\hat{B}$ both possess the eigenbasis $\{\gamma_{i}\}$. We want to prove they commute. As they possess the same eigenbasis with eigenvalues $\{A_{i}\}$ and $\{B_{i}\}$ respectively, we can write
$$
\hat{A}\hat{B}\gamma_{i}=\hat{A}B_{i}\gamma_{i}=B_{i}\hat{A}\gamma_{i}=B_{i}A_{i}\gamma_{i}
$$
and the exact same applies for $\hat{B}\hat{A}\gamma_{i}$:
$$
\hat{B}\hat{A}\gamma_{i}=\hat{B}A_{i}\gamma_{i}=A_{i}\hat{B}\gamma_{i}=A_{i}B_{i}\gamma_{i}.
$$
Clearly, as $A_{i}$ and $B_{i}$ are constant eigenvalues, 
$$
A_{i}B_{i}\equiv B_{i}A_{i}.
$$
So this easily proves that two observable operators possessing the same eigenbasis must commute. Thus the implication works both ways and therefore two observable operators commute iff they share a common eigenbasis.
\\\\
Now to look at the practical definition: we are probably more interested in the concept of compatibility, as it concerns whether or not a measurement of a second observable in between measurements of a first observable will alter the measured results from the first measurement, effectively  forcing the state vector out of the pure eigenstate it was forced into. Let's first prove that two observables having common operator eigenbases is necessary and sufficient for the above defined definition of compatibility to hold.
\\\\
Start by considering two observables $\mathcal{A}$ and $\mathcal{B}$ represented by operators $\hat{A}$ and $\hat{B}$ respectively. Define the measurements to be $\mathcal{A}^{(1)},\mathcal{B}^{(1)}$, $\mathcal{A}^{(2)}$. For the observables to be compatible we need $\mathcal{A}^{(1)}$ to be the same as $\mathcal{A}^{(2)}$ regardless of the starting state and $\mathcal{B}^{(2)}$. Assume to begin with that the two operators $\hat{A}$ and $\hat{B}$ have the common eigenbasis $\{\gamma_{i}\}$. By definition the first measurement of $\mathcal{A}$ must force the state vector into a single eigenvector in the eigenbasis of the operator $\hat{A}$: that is, some $\gamma_{i}$ such that the measured value is for observable $\mathcal{A}$ the eigenvalue $A_{i}$. Next, measurement ${{B}}^{(1)}$ is the action of the operator $\hat{B}$ on the eigenvector $\gamma_{i}$. But by the Measurement Postulate of quantum mechanics,
$$
P(\bm{\alpha}_{i})=|\oip{\bm{\alpha}_{i}}{\Psi}|^2
$$
That is, the probability that the arbitrary operator $\hat{A}$ forces the state vector into an arbitrary eigenvector $\bm{\alpha}_{i}$ from its eigenbasis. Here, then, since the state vector has been forced into the eigenstate $\gamma_{i}$ by the first measurement, the probability the second measurement of the other observable $\mathcal{B}$ forces the state vector into the same eigenstate is:
$$
P(\gamma_{i})=|\oip{\gamma_{i}}{\gamma_{i}}|^2=1
$$
where we assume as per usual that the eigenvectors $\gamma_{i}$ have been normalised. So we can say that measurement B will not alter the eigenstate the state vector is in and therefore the third measurement will follow the same logic to yield the exact same value, the eigenvalue $A_{i}$ corresponding to $\gamma_{i}$. Thus, if two observable operators possess the same eigenbasis, they are compatible observables.
\\\\
If the observables are compatible then this implies their operators have the same eigenbasis. The proof for this is simple. If the observables $\mathcal{A}$ and $\mathcal{B}$ are compatible then for the successive measurements $\mathcal{A}^{(1)},\mathcal{B}^{(1)},\mathcal{A}^{(2)}$ the measured values for $\mathcal{A}^{(1)}$ and $\mathcal{A}^{(2)}$ must be the same. The measurement $\mathcal{A}^{(1)}$ must have forced the wavefunction into an eigenvector of $\hat{A}$, some arbitrary $\bm{\alpha}_{i}$. Then, the measurement $\mathcal{B}^{(1)}$ must force the wavefunction into some arbitrary eigenvector $\bm{\beta}_{i}$ of the operator $\hat{B}$. However, the final measurement must yield the same result as the first if the observables are compatible, which is, the same eigenvalue corresponding to the same eigenvector $\bm{\alpha}_{i}$ of operator $\hat{A}$ as it originally was in. The probability that the measurement forces the wavefunction, currently in the eigenstate $\bm{\beta}_{i}$ of $\hat{B}$ as the measurement $\mathcal{B}^{(1)}$ has just been performed, into the same eigenstate $\bm{\alpha}_{i}$ as originally measured is:
$$
P(\bm{\alpha}_{i})=|\oip{\bm{\alpha}_{i}}{\bm{\beta}_{i}}|^2.
$$
However, if these observables are to be compatible, the final measurement must with certainty yield the eigenvalue $A_{i}$ again and therefore the above probability of measurement $\mathcal{A}^{(2)}$ forcing it back into the original eigenstate must be 1. So 
$$
|\oip{\bm{\alpha}_{i}}{\bm{\beta}_{i}}|^2=1 \Rightarrow\:\: \bm{\alpha}_{i}\equiv\bm{\beta}_{i}
$$
and therefore their eigenbases must be the same as the above holds true for any arbitrary $\bm{\alpha}_{i}$ and corresponding $\bm{\beta}_{i}$ from the measurements.
\\\\
The Compatibility Theorem is now complete. We have shown that:
\begin{itemize}
    \item Two operators commuting is necessary and sufficient for them to possess a common eigenbasis.
    \item Two operators possessing a common eigenbasis is necessary and sufficient for the two observables they represent to be compatible.
    \item Therefore, two observable operators commuting is also necessary and sufficient for them to represent compatible observables.
\end{itemize}
The logical implications of these facts all run three ways.
\\\\
While we have now seen facts about compatible observables, an example of incompatible observables sticks in our mind-- that of the Stern Gerlach experiment. We saw exactly that $x$ and $y$ spins were incompatible, because measuring the $x$ spin in between two $y$ measurements stopped the second $y$ measurement from being the same as the first with certainty-- which is to say, we now know, that the measurement of $x$ spin forced it out of the eigenstate of $y$ spin it had been previously forced into. All the questions about the quantum state raised by the Stern Gerlach experiment will finally come to an end with this section. We would like to formalise our understanding of how incompatibility affected the experiment. To explain it all, we witness-- and prove ourselves!-- one of Physics' most groundbreaking and shocking theorems.
\section{The Heisenberg Uncertainty Principle}
The idea of commuting observable operators being necessary and sufficient for the two observables they represent to be compatible is a very important one for the question of simultaneous states, and has been shown above. Now we must surely consider when two observable operators do not commute: in other words, when they represent \textbf{incompatible} observables. One of the most important and dramatic results of all quantum mechanics, the Heisenberg Uncertainty Principle, results when we carry out some elegant mathematics to investigate this problem. Before we begin the statement and proof, let us define the commutator between two operators to be 
$$
[\hat{A},\hat{B}]:=\hat{A}\hat{B}-\hat{B}\hat{A}
$$
so that if we have two commuting operators $\hat{A}$ and $\hat{B}$, then 
$$
[\hat{A},\hat{B}]=\hat{A}\hat{B}-\hat{B}\hat{A}=0
$$
since $\hat{A}\hat{B}=\hat{B}\hat{A}$ iff they commute. For operators which do not commute, their commutator may take a wide variety of forms: which is why it is useful under universal convention to have this shorthand.
\begin{tcolorbox}
\textbf{\underline{Heisenberg Uncertainty Principle}}\\\\
For any state $\Psi_{t}$,
$$
\Delta A_{t}\Delta B_{t}\geq\frac{1}{2}|\oip{\Psi_{t}}{[\hat{A},\hat{B}]\Psi_{t}}|
$$
where $\Delta A_{t}$ is the standard deviation of measurable values of observable $\mathcal{A}$ at time $t$: which is therefore a measure of uncertainty for these variables.
\end{tcolorbox}
\underline{\textbf{Proof:}}\\\\
We will continue to refer to arbitrary observables $\mathcal{A}$ and $\mathcal{B}$ for the proof; all the proof is relevant at any instant of time and so time subscripts will be eschewed. The notation $\Delta A$ refers to the standard deviation of the measurements of observable $\mathcal{A}$; this standard deviation is no different from the statistical definition:
$$
\Delta A=\sqrt{\langle \hat{A}^2\rangle-\langle \hat{A}\rangle^2}
$$
where the symbol $\langle X\rangle$ is the expected value of the variable $X$, as seen in the probability preliminary. First we note that this principle is valid for compatible observables: as compatible observables, their operators must commute. Thus
$$
[\hat{A},\hat{B}]=0 \Rightarrow\:\: \Delta A_{t}\Delta B_{t}\geq\frac{1}{2}|\oip{\Psi_{t}}{[\hat{A},\hat{B}]\Psi_{t}}| = \frac{1}{2}|\oip{\Psi_{t}}{0} |=0. 
$$
So for compatible observables, 
$$
\Delta A_{t}\Delta B_{t}\geq 0
$$
which is neither interesting nor invalid at all since the standard deviation of any measurement can never be negative. Now, we will prove this for all physical operators, regardless of whether they commute.
\\\\
\underline{\textbf{Lemma 1:}}\\
Any operator $\hat{X}':=\hat{X}-\qexp{\hat{X}}$ where $\hat{X}$ is a Hermitian physical operator is also Hermitian.\\\\
\underline{\textbf{Proof:}}\\\\
Recall that the definition for an expected value of a variable is the sum of its possible values multiplied by the probabilities of the variable taking those values. Therefore, we can say that, over the eigenbasis $\{\xi_{i}\}$ of $\hat{X}$ with eigenvalues $\{X_{i}\}$, 
$$
\qexp{\hat{X}}=\sum_{\{i\}}P(\xi_{i})X_{i},
$$
but by our knowledge of the previous postulates we can describe the probability more precisely: the measurement postulate defines this to be
$$
\qexp{\hat{X}}=\sum_{\{i\}}X_{i}|\oip{\xi_{i}}{\Psi}|^2.
$$
Our job is to prove that the operator $\hat{X}':=\hat{X}-\qexp{\hat{X}}$ is hermitian if $\hat{X}$ is hermitian for all quantum operators. That is, we need to prove that:
$$
\oip{\Psi_{1}}{\hat{X}'\Psi_{2}}=\oip{\hat{X}'\Psi_{1}}{\Psi_{2}}
$$
for all Hilbert space functions $\Psi_{1}$ and $\Psi_{2}$. The operator $\hat{X}$ must be hermitian as $\hat{X}$ is defined to be a quantum operator corresponding to a physical observable. Meanwhile, the expectation value
$$
\qexp{\hat{X}}=\sum_{\{i\}}X_{i}|\oip{\xi_{i}}{\Psi}|^2.
$$
is clearly a real scalar, as the probabilities, which are square moduli, will all be real numbers and so will each eigenvalue of the hermitian operators. Therefore, 
$$
\oip{\hat{X}\Psi_{1}}{\Psi_{2}}\equiv\oip{\Psi_{1}}{\hat{X}\Psi_{2}}
$$
and 
$$
\oip{\qexp{\hat{X}}\Psi_{1}}{\Psi_{2}}\equiv\oip{\Psi_{1}}{\langle\hat{X}\rangle\Psi_{2}}\equiv\qexp{\hat{X}}\oip{\Psi_{1}}{\Psi_{2}}
$$
so for any physical operator $\hat{X}$ the defined operator $\hat{X}'$ is the sum of two hermitian operators. So
$$
\begin{aligned}
\oip{\hat{X}'\Psi_{1}}{\Psi_{2}}&=\oip{[\hat{X}-\langle\hat{X}\rangle]\Psi_{1}}{\Psi_{2}}=\oip{\hat{X}\Psi_{1}}{\Psi_{2}}-\oip{\langle\hat{X}\rangle\Psi_{1}}{\Psi_{2}}\\
&=\oip{\Psi_{1}}{\hat{X}\Psi_{2}}-\oip{\Psi_{1}}{\langle\hat{X}\rangle\Psi_{2}}\\
&=\oip{\Psi_{1}}{\hat{X}'\Psi_{2}}
\end{aligned}
$$
using the linear properties of the inner product. Thus, the operator $\hat{X}'$ is Hermitian for any physical operator. Therefore, defining $\hat{A'}:=\hat{A}-\qexp{\hat{A}}$ and $\hat{B}':=\hat{B}-\qexp{\hat{B}}$ for the purpose of the problem also gives us two hermitian operators. $\square$
\\\\
The commutator in the generalised principle might give pause with regards to the development of these new operators, but, importantly,
$$
[\hat{A}',\hat{B}']=[\hat{A},\hat{B}].
$$
This fact can be proved quite simply:
$$
\begin{aligned}
[\hat{A}',\hat{B}']&= \hat{A}'\hat{B}'- \hat{A}'\hat{B}'\\
&= (\hat{A}-\qexp{\hat{A}})(\hat{B}-\qexp{\hat{B}})-(\hat{B}-\qexp{\hat{B}}) (\hat{A}-\qexp{\hat{A}})\\
&=(\hat{A}\hat{B}-\hat{A}\qexp{\hat{B}}-\qexp{\hat{A}}\hat{B}-\qexp{\hat{A}}\qexp{\hat{B}})-(\hat{B}\hat{A}-\hat{B}\qexp{\hat{A}}-\qexp{\hat{B}}\hat{A}-\qexp{\hat{B}}\qexp{\hat{A}})
\end{aligned}
$$
but as the expectation values $\qexp{\hat{A}}$ and $\qexp{\hat{B}}$ are real scalars it is clear that $\qexp{\hat{A}}\qexp{\hat{B}}=\qexp{\hat{B}}\qexp{\hat{A}}$, and $\qexp{\hat{A}}\hat{B}=\hat{B}\qexp{\hat{A}}$ and vice versa swapping the $A$ and $B$ around. So the terms cancel out and we are left with
$$
[\hat{A}',\hat{B}']=\hat{A}\hat{B}-\hat{B}\hat{A}:=[\hat{A},\hat{B}]. \:\:\square
$$
Now, one last important lemma:\\\\
\underline{\textbf{Lemma 2:}}\\
$$\oip{\hat{A}'\Psi}{\hat{A}'\Psi}=(\Delta\hat{A})^2$$
\\\\
\underline{\textbf{Proof:}}\\
By the Hermiticity of $\hat{A}'$,
$$
\oip{\hat{A}'\Psi}{\hat{A}'\Psi}=\oip{\Psi}{([\hat{A}']^2\Psi}.
$$
Expanding the definition,
$$
\begin{aligned}
\oip{\hat{A}'\Psi}{\hat{A}'\Psi}&=\oip{\Psi}{\hat{A}'^2\Psi}\\
&=\oip{\Psi}{[\hat{A}-\qexp{\hat{A}}][\hat{A}-\qexp{\hat{A}}]\Psi}\\
&=\oip{\Psi}{[\hat{A}^{2}]\Psi-2\qexp{\hat{A}}\hat{A}\Psi+\qexp{\hat{A}}^2\Psi}\\
&=\oip{\Psi}{[\hat{A}^{2}]\Psi}-2\qexp{\hat{A}}\oip{\Psi}{\hat{A}\Psi}+\qexp{\hat{A}}^2\oip{\Psi}{\Psi}\\
&=\langle\hat{A}^2\rangle\oip{\Psi}{\Psi}-2\qexp{\hat{A}}\qexp{\hat{A}}\oip{\Psi}{\Psi}+\qexp{\hat{A}}^2\oip{\Psi}{\Psi}\\
&= \langle\hat{A}^2\rangle-2\qexp{\hat{A}}\qexp{\hat{A}}+\qexp{\hat{A}}^2\\
&=\langle\hat{A}^2\rangle-\qexp{\hat{A}}^2\\
&=(\Delta\hat{A})^2 \:\:\:\:\:\:\square
\end{aligned}
$$
Now we can use these lemmas to prove the problem. We want to prove that 
$$
\Delta{A}\Delta{B}\geq\frac{1}{2}|\oip{\Psi}{[\hat{A},\hat{B}]\Psi}|
$$
at all times $t$. We start by replacing $[\hat{A},\hat{B}]$ with $[\hat{A}',\hat{B}']$. Then, we have,
$$
\oip{\Psi}{[\hat{A},\hat{B}]\Psi}=\oip{\Psi}{[\hat{A}',\hat{B}']\Psi}=\oip{\Psi}{[\hat{A}'\hat{B}'-\hat{B}'\hat{A}']\Psi}.
$$
This is, 
$$
\oip{\Psi}{[\hat{A},\hat{B}]\Psi}=\oip{\Psi}{\hat{A}'\hat{B}'\Psi}-\oip{\Psi}{\hat{B}'\hat{A}'\Psi}
.$$
We can rearrange this by the hermiticity of $\hat{A}'$ and $\hat{B}'$:
$$
\oip{\Psi}{[\hat{A},\hat{B}]\Psi}=\oip{\hat{A}'\Psi}{\hat{B}'\Psi}-\oip{\hat{B}'\Psi}{\hat{A}'\Psi}=\oip{\hat{A}'\Psi}{\hat{B}'\Psi}-\oip{\hat{A}'\Psi}{\hat{B}'\Psi}^{\ast}
$$
so this is
$$
\oip{\Psi}{[\hat{A},\hat{B}]\Psi}=2i\text{Im}\left(\oip{\hat{A}'\Psi}{\hat{B}'\Psi}\right)
$$
according to rudimentary arithmetic of complex numbers. Then, the expression we need is
$$
\frac{1}{2}|\oip{\Psi}{[\hat{A},\hat{B}]\Psi}|\leq\frac{1}{2}\times2|\oip{\hat{A}'\Psi}{\hat{B}'\Psi}|=|\oip{\hat{A}'\Psi}{\hat{B}'\Psi}|.
$$
This is because of the above expression for $\oip{\Psi}{[\hat{A},\hat{B}]\Psi}$ and the fact that the modulus of the imaginary part of a scalar cannot be greater than the modulus of the scalar (Exercise 1.3.2a). Then, by Lemma 2
$$
\oip{\hat{A}'\Psi}{\hat{A}'\Psi}=(\Delta\hat{A})^2\Rightarrow\:\:\Delta\hat{A}=\sqrt{\oip{\hat{A}'\Psi}{\hat{A}'\Psi}}.
$$
So 
$$
\Delta\hat{A}\Delta\hat{B}=\sqrt{\oip{\hat{A}'\Psi}{\hat{A}'\Psi}}\sqrt{\oip{\hat{B}'\Psi}{\hat{B}'\Psi}}.
$$
By Cauchy-Schwartz, 
$$
\sqrt{\oip{\hat{A}'\Psi}{\hat{A}'\Psi}}\sqrt{\oip{\hat{B}'\Psi}{\hat{B}'\Psi}}\geq|\oip{\hat{A}'\Psi}{\hat{B}'\Psi}|
$$
and so, conclusively,
$$
\Delta\hat{A}\Delta\hat{B}=\sqrt{(\hat{A}'\Psi,\hat{A}'\Psi)}\sqrt{(\hat{B}'\Psi,\hat{B}'\Psi)}\geq|\oip{\hat{A}'\Psi}{\hat{B}'\Psi}|\geq\frac{1}{2}|\oip{\Psi}{[\hat{A},\hat{B}]\Psi}|
$$
so 
$$
\Delta\hat{A}\Delta\hat{B}\geq\frac{1}{2}|\oip{\Psi}{[\hat{A},\hat{B}]\Psi}|.
$$
This proves Heisenberg's Uncertainty Principle. $\square$
\\\\
This general form we have above is still difficult to interpret, but if we consider a few examples we will realise this is a very important result. One of the most famous iterations comes with considering simply the two central operators of quantum mechanics: the position and momentum operators, which we have not yet introduced but will for now just use for calculation purposes. We can calculate the commutator:
$$
\begin{aligned}
&[\hat{X},\hat{P}]=\hat{X}\hat{P}-\hat{P}\hat{X}\\
\Rightarrow\:\:&[\hat{X},\hat{P}]\Psi(x)=-xi\hbar\frac{\partial}{\partial x}\Psi(x)--i\hbar\frac{\partial}{\partial x}\biggl(x\Psi(x)\biggr)\\
\Rightarrow\:\:&[\hat{X},\hat{P}]\Psi(x)=-i\hbar x\frac{\partial \Psi}{\partial x}--i\hbar\biggl[\frac{dx}{dx}\Psi(x)+x\frac{\partial\Psi}{\partial x}\biggr]\\
\Rightarrow\:\:&[\hat{X},\hat{P}]\Psi(x)=-i\hbar\biggl[x\frac{\partial\Psi}{\partial x}-\Psi(x)-x\frac{\partial\Psi}{\partial x}\biggr]\\
\Rightarrow\:\:&[\hat{X},\hat{P}]\Psi(x)=i\hbar\Psi(x)\\
\Rightarrow\:\:&[\hat{X},\hat{P}]\equiv i\hbar.
\end{aligned}
$$
After this, if we plug this into the Generalised Uncertainty principle and assume that the wavefunction is normalised,
$$
\Delta{\hat{X}}\Delta{\hat{P}}\geq\frac{1}{2}|\oip{\Psi}{i\hbar\Psi}| \Rightarrow \Delta{\hat{X}}\Delta{\hat{P}}\geq\frac{1}{2}|i\hbar\oip{\Psi}{\Psi}|=\frac{1}{2}|i\hbar|=\frac{1}{2}\sqrt{-i\hbar\times i\hbar}=\frac{\hbar}{2}.
$$
The key end result is that 
$$
\Delta{\hat{X}}\Delta{\hat{P}}\geq\frac{\hbar}{2}.
$$
This is the most well known form of the Uncertainty Principle, but we can see that the Generalised Uncertainty Principle can be applied more broadly than just to the two observables of position and momentum. 
\\\\
Returning to our considerations of the physical results of trying to measure two incompatible observables, it is clear how bizarre this result is. Consider if we have just made a measurement for the position of a particle. Then we have forced its wavefunction into a position eigenstate and therefore we can say that the uncertainty in the position is now $0$: we know the successive measurement must yield the same position value with probability 1. However, if we plug in $\Delta{\hat{X}}$ into the Uncertainty Principle we get 
$$
0\times\Delta\hat{P}\geq\frac{\hbar}{2}
$$
which implies somehow that the uncertainty in momentum must be infinite! So if we know the value of the position with certainty we are completely unable to distinguish between infinite possibilities for the momentum. The relationship works both ways so the same applies for the momentum: if we know the momentum of a particle then we necessarily have infinite uncertainty in the position of the particle and we have not a clue where it is. This is undoubtedly one of the most anti-classical results in quantum mechanics, and yet it results beautifully from the mathematics we have defined (and has never been experimentally refuted). If nothing else, it should now be clear that the mathematical manipulations of quantum mechanics are rich and impactful.
\\\\
The same is manifested, of course, in the Stern-Gerlach experiment. By knowing $x$ spin, we had infinite uncertainty in $y$ spin- with absolutely no way to tell if an electron would be up or down spin. By knowing the $y$ spin, we had infinite uncertainty in the $x$ spin. This is one example of an experimental verification of the Heisenberg Uncertainty Principle.
\\\\
Now, we are ready to move onto time evolution.